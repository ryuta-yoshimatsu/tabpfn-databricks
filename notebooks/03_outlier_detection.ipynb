{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Outlier Detection on Databricks\n",
        "\n",
        "This notebook demonstrates outlier detection techniques on Databricks, comparing TabPFN-based approaches with traditional methods.\n",
        "\n",
        "**What you will learn:**\n",
        "- How to use TabPFN for anomaly scoring via classification\n",
        "- How to evaluate and visualize anomaly scores\n",
        "- How to compare with traditional outlier detection methods\n",
        "\n",
        "**Prerequisites:** Run `00_data_preparation` notebook first to set up the datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute Setup\n",
        "\n",
        "We recommend running this notebook on **Serverless Compute** with the **Base Environment V4**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install tabpfn-client scikit-learn pandas matplotlib seaborn --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dbutils.library.restartPython()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Authentication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tabpfn_client\n",
        "\n",
        "token = dbutils.secrets.get(scope=\"tabpfn-client\", key=\"token\")\n",
        "tabpfn_client.set_access_token(token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CATALOG = \"tabpfn_databricks\"\n",
        "SCHEMA = \"default\"\n",
        "\n",
        "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
        "spark.sql(f\"USE SCHEMA {SCHEMA}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from tabpfn_client import TabPFNClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Synthetic Data Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate synthetic data with known outliers\n",
        "np.random.seed(42)\n",
        "\n",
        "n_normal = 200\n",
        "X_normal = np.random.randn(n_normal, 2) * 0.5 + np.array([2, 2])\n",
        "\n",
        "n_outliers = 20\n",
        "X_outliers = np.random.uniform(-2, 6, size=(n_outliers, 2))\n",
        "\n",
        "X_synthetic = np.vstack([X_normal, X_outliers])\n",
        "y_true = np.array([0] * n_normal + [1] * n_outliers)\n",
        "\n",
        "print(f\"Dataset shape: {X_synthetic.shape}\")\n",
        "print(f\"Normal samples: {n_normal}, Outliers: {n_outliers}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the data\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "ax.scatter(X_synthetic[y_true == 0, 0], X_synthetic[y_true == 0, 1], c='blue', label='Normal', alpha=0.6)\n",
        "ax.scatter(X_synthetic[y_true == 1, 0], X_synthetic[y_true == 1, 1], c='red', label='Outlier', marker='x', s=100)\n",
        "ax.set_xlabel('Feature 1')\n",
        "ax.set_ylabel('Feature 2')\n",
        "ax.set_title('Synthetic Data with Known Outliers')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. TabPFN-based Anomaly Detection\n",
        "\n",
        "We use TabPFN as a classifier trained on a subset of normal data to score anomalies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train TabPFN on normal samples to learn the \"normal\" distribution\n",
        "# Then use it to score how \"abnormal\" each point is\n",
        "\n",
        "# Create a semi-supervised setup: train on labeled normal data\n",
        "X_train = X_normal[:150]  # Use 150 normal samples for training\n",
        "y_train = np.zeros(150)   # All labeled as normal (0)\n",
        "\n",
        "# Add a few synthetic outliers to training to teach the model\n",
        "X_train_outliers = np.random.uniform(-2, 6, size=(15, 2))\n",
        "X_train = np.vstack([X_train, X_train_outliers])\n",
        "y_train = np.concatenate([y_train, np.ones(15)])  # Label outliers as 1\n",
        "\n",
        "clf = TabPFNClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Score all points - probability of being an outlier\n",
        "anomaly_scores_tabpfn = clf.predict_proba(X_synthetic)[:, 1]\n",
        "\n",
        "roc_auc_tabpfn = roc_auc_score(y_true, anomaly_scores_tabpfn)\n",
        "print(f\"TabPFN ROC AUC: {roc_auc_tabpfn:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Comparison with Traditional Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_synthetic)\n",
        "\n",
        "# Isolation Forest\n",
        "iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
        "iso_forest.fit(X_scaled)\n",
        "scores_iso = -iso_forest.score_samples(X_scaled)\n",
        "\n",
        "# Local Outlier Factor\n",
        "lof = LocalOutlierFactor(n_neighbors=20, novelty=False, contamination=0.1)\n",
        "lof.fit(X_scaled)\n",
        "scores_lof = -lof.negative_outlier_factor_\n",
        "\n",
        "# Evaluate all methods\n",
        "methods = {\n",
        "    \"TabPFN (semi-supervised)\": anomaly_scores_tabpfn,\n",
        "    \"Isolation Forest\": scores_iso,\n",
        "    \"Local Outlier Factor\": scores_lof,\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, scores in methods.items():\n",
        "    roc = roc_auc_score(y_true, scores)\n",
        "    results[name] = roc\n",
        "    print(f\"{name:30s}: ROC AUC = {roc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize comparison\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "colors = ['#2ecc71' if 'TabPFN' in name else '#3498db' for name in results.keys()]\n",
        "bars = ax.barh(list(results.keys()), list(results.values()), color=colors)\n",
        "ax.set_xlabel('ROC AUC Score')\n",
        "ax.set_title('Outlier Detection Method Comparison')\n",
        "ax.set_xlim(0.5, 1.0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, we demonstrated:\n",
        "\n",
        "- ✅ Using TabPFN for semi-supervised anomaly detection\n",
        "- ✅ Comparing with traditional methods (Isolation Forest, LOF)\n",
        "- ✅ Evaluating with ROC AUC metric"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
