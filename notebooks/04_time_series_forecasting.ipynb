{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Demand Forecasting with TabPFN Time Series\n",
        "\n",
        "This notebook demonstrates time series forecasting for demand planning using TabPFN's native time series capabilities.\n",
        "\n",
        "**Use Case:** Demand Planning - Forecast product demand by category and region\n",
        "\n",
        "**Business Context:** Accurate demand forecasting is the foundation of supply chain planning. It drives:\n",
        "- Inventory planning and safety stock optimization\n",
        "- Production scheduling and capacity planning\n",
        "- Distribution requirements planning (DRP)\n",
        "- Procurement and supplier management\n",
        "\n",
        "**What you will learn:**\n",
        "- How to use TabPFN's TimeSeriesDataFrame for time series data\n",
        "- How to apply automatic feature engineering with FeatureTransformer\n",
        "- How to use TabPFNTimeSeriesPredictor for forecasting\n",
        "- How to evaluate forecast accuracy with industry-standard metrics\n",
        "- How to forecast across multiple series and aggregate for planning\n",
        "\n",
        "**Prerequisites:** Run `00_data_preparation` notebook first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute Setup\n",
        "\n",
        "We recommend running this notebook on a cluster with **DBR 17.4 LTS for ML** or above for the best experience. This runtime includes optimized ML libraries and better compatibility with TabPFN Time Series."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install tabpfn-client tabpfn-time-series scikit-learn pandas matplotlib mlflow --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dbutils.library.restartPython()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Authentication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tabpfn_client\n",
        "\n",
        "token = dbutils.secrets.get(scope=\"tabpfn-client\", key=\"token\")\n",
        "tabpfn_client.set_access_token(token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CATALOG = \"tabpfn_databricks\"\n",
        "SCHEMA = \"default\"\n",
        "\n",
        "# MLflow experiment configuration (shared across all TabPFN notebooks)\n",
        "# Default uses user namespace, but can be customized\n",
        "current_user = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
        "MLFLOW_EXPERIMENT_NAME = f\"/Users/{current_user}/tabpfn-databricks\"\n",
        "\n",
        "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
        "spark.sql(f\"USE SCHEMA {SCHEMA}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import mlflow\n",
        "\n",
        "# TabPFN Time Series imports\n",
        "from tabpfn_time_series import (\n",
        "    TimeSeriesDataFrame,\n",
        "    FeatureTransformer,\n",
        "    TabPFNTimeSeriesPredictor,\n",
        "    TabPFNMode,\n",
        ")\n",
        "from tabpfn_time_series.data_preparation import generate_test_X\n",
        "from tabpfn_time_series.features import RunningIndexFeature, CalendarFeature, AutoSeasonalFeature\n",
        "\n",
        "# Set MLflow experiment\n",
        "mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)\n",
        "print(f\"MLflow experiment set to: {MLFLOW_EXPERIMENT_NAME}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Load Demand Forecast Data\n",
        "\n",
        "The demand forecast dataset contains monthly demand data across:\n",
        "- Multiple product categories (Beverages, Snacks, Dairy, Frozen, Personal Care)\n",
        "- Multiple regions (Northeast, Southeast, Midwest, West)\n",
        "\n",
        "Each series exhibits realistic patterns including:\n",
        "- Seasonality (annual patterns)\n",
        "- Trend (growth or decline)\n",
        "- Holiday effects\n",
        "- Random noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load demand forecast training data\n",
        "df_demand = spark.table(\"demand_forecast_train\").toPandas()\n",
        "df_demand['date'] = pd.to_datetime(df_demand['date'])\n",
        "\n",
        "print(f\"Dataset shape: {df_demand.shape}\")\n",
        "print(f\"Number of time series: {df_demand['series_id'].nunique()}\")\n",
        "print(f\"Time range: {df_demand['date'].min().strftime('%Y-%m')} to {df_demand['date'].max().strftime('%Y-%m')}\")\n",
        "print(f\"\\nCategory distribution:\")\n",
        "print(df_demand['category'].value_counts())\n",
        "\n",
        "display(df_demand.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize sample time series\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Get one series from each category\n",
        "categories = df_demand['category'].unique()[:4]\n",
        "\n",
        "for ax, cat in zip(axes.flatten(), categories):\n",
        "    series_id = df_demand[df_demand['category'] == cat]['series_id'].iloc[0]\n",
        "    df_s = df_demand[df_demand['series_id'] == series_id].sort_values('date')\n",
        "    \n",
        "    ax.plot(df_s['date'], df_s['demand_units'], 'b-', linewidth=1.5, marker='o', markersize=3)\n",
        "    ax.set_title(f'{cat} ({df_s[\"region\"].iloc[0]})')\n",
        "    ax.set_xlabel('Date')\n",
        "    ax.set_ylabel('Demand (Units)')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Convert to TimeSeriesDataFrame\n",
        "\n",
        "TabPFN Time Series uses a specialized `TimeSeriesDataFrame` format that indexes data by `item_id` (series identifier) and `timestamp`. This enables efficient handling of multiple time series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pandas_to_time_series_dataframe(df, item_id_col, timestamp_col, target_col):\n",
        "    \"\"\"\n",
        "    Convert a pandas DataFrame to a TimeSeriesDataFrame.\n",
        "    \n",
        "    Args:\n",
        "        df: pandas DataFrame with time series data\n",
        "        item_id_col: Column name for series identifier\n",
        "        timestamp_col: Column name for timestamps\n",
        "        target_col: Column name for target values\n",
        "    \n",
        "    Returns:\n",
        "        TimeSeriesDataFrame\n",
        "    \"\"\"\n",
        "    # Prepare the data with proper index\n",
        "    df_ts = df[[item_id_col, timestamp_col, target_col]].copy()\n",
        "    df_ts = df_ts.rename(columns={\n",
        "        item_id_col: 'item_id',\n",
        "        timestamp_col: 'timestamp',\n",
        "        target_col: 'target'\n",
        "    })\n",
        "    df_ts = df_ts.sort_values(['item_id', 'timestamp'])\n",
        "    df_ts = df_ts.set_index(['item_id', 'timestamp'])\n",
        "    \n",
        "    return TimeSeriesDataFrame(df_ts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert to TimeSeriesDataFrame\n",
        "tsdf = pandas_to_time_series_dataframe(\n",
        "    df_demand,\n",
        "    item_id_col='series_id',\n",
        "    timestamp_col='date',\n",
        "    target_col='demand_units'\n",
        ")\n",
        "\n",
        "print(f\"TimeSeriesDataFrame created with {len(tsdf.item_ids)} series\")\n",
        "print(f\"Item IDs: {tsdf.item_ids[:5]}...\")\n",
        "print(f\"\\nDataFrame shape: {tsdf.shape}\")\n",
        "display(tsdf.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Single Series Forecasting Demo\n",
        "\n",
        "Let's first demonstrate forecasting on a single series to understand the workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select a single series for demonstration\n",
        "selected_series = tsdf.item_ids[0]\n",
        "tsdf_single = tsdf[tsdf.index.get_level_values('item_id') == selected_series]\n",
        "\n",
        "# Get series metadata from original dataframe\n",
        "series_info = df_demand[df_demand['series_id'] == selected_series].iloc[0]\n",
        "\n",
        "print(f\"Selected series: {selected_series}\")\n",
        "print(f\"Category: {series_info['category']}\")\n",
        "print(f\"Region: {series_info['region']}\")\n",
        "print(f\"Series length: {len(tsdf_single)} months\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define forecast horizon\n",
        "pred_len = 6  # Forecast 6 months ahead\n",
        "\n",
        "# Split into training and test portions\n",
        "train_single, test_single = tsdf_single.train_test_split(prediction_length=pred_len)\n",
        "\n",
        "# Generate test features (X) for the forecast horizon\n",
        "test_X_single = generate_test_X(train_single, pred_len)\n",
        "\n",
        "print(f\"Training samples: {len(train_single)}\")\n",
        "print(f\"Test samples: {len(test_single)} (forecast horizon: {pred_len} months)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add temporal and seasonal features using FeatureTransformer\n",
        "features = [\n",
        "    RunningIndexFeature(),  # Sequential index feature\n",
        "    CalendarFeature(),      # Month, day of week, etc.\n",
        "    AutoSeasonalFeature()   # Automatic seasonality detection\n",
        "]\n",
        "\n",
        "transformer = FeatureTransformer(features)\n",
        "train_single_feat, test_X_single_feat = transformer.transform(train_single, test_X_single)\n",
        "\n",
        "print(f\"Training features shape: {train_single_feat.shape}\")\n",
        "print(f\"Test features shape: {test_X_single_feat.shape}\")\n",
        "print(f\"\\nFeature columns: {list(train_single_feat.columns)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Train TabPFN Time Series Predictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the predictor (client mode uses pretrained TabPFN weights)\n",
        "predictor = TabPFNTimeSeriesPredictor(tabpfn_mode=TabPFNMode.CLIENT)\n",
        "\n",
        "# Generate forecasts with MLflow logging\n",
        "with mlflow.start_run(run_name=\"demand_forecast_single_series\"):\n",
        "    # Log parameters\n",
        "    mlflow.log_param(\"model_type\", \"TabPFNTimeSeriesPredictor\")\n",
        "    mlflow.log_param(\"tabpfn_mode\", \"CLIENT\")\n",
        "    mlflow.log_param(\"task\", \"demand_forecasting\")\n",
        "    mlflow.log_param(\"series_id\", selected_series)\n",
        "    mlflow.log_param(\"category\", series_info['category'])\n",
        "    mlflow.log_param(\"region\", series_info['region'])\n",
        "    mlflow.log_param(\"forecast_horizon\", pred_len)\n",
        "    mlflow.log_param(\"n_features\", train_single_feat.shape[1])\n",
        "    mlflow.log_param(\"train_samples\", len(train_single_feat))\n",
        "    \n",
        "    # Make predictions\n",
        "    pred_single = predictor.predict(train_single_feat, test_X_single_feat)\n",
        "    \n",
        "    # Extract actual values for evaluation\n",
        "    # Note: train_test_split returns the full series as the second element,\n",
        "    # so we extract only the last pred_len values from the original series\n",
        "    y_test = tsdf_single['target'].values[-pred_len:]\n",
        "    y_pred = pred_single['mean'].values if 'mean' in pred_single.columns else pred_single.iloc[:, 0].values\n",
        "    \n",
        "    # Calculate forecast metrics\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "    \n",
        "    # Calculate bias\n",
        "    bias = np.mean(y_pred - y_test)\n",
        "    bias_pct = (bias / np.mean(y_test)) * 100\n",
        "    \n",
        "    # Log metrics\n",
        "    mlflow.log_metric(\"mae\", mae)\n",
        "    mlflow.log_metric(\"rmse\", rmse)\n",
        "    mlflow.log_metric(\"mape\", mape)\n",
        "    mlflow.log_metric(\"bias\", bias)\n",
        "    mlflow.log_metric(\"bias_pct\", bias_pct)\n",
        "    \n",
        "    print(f\"Forecast Metrics ({pred_len}-month horizon):\")\n",
        "    print(f\"  MAE:  {mae:,.0f} units\")\n",
        "    print(f\"  RMSE: {rmse:,.0f} units\")\n",
        "    print(f\"  MAPE: {mape:.1f}%\")\n",
        "    print(f\"  Bias: {bias:,.0f} units ({bias_pct:+.1f}%)\")\n",
        "    print(f\"  MLflow Run ID: {mlflow.active_run().info.run_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize forecast\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "# Get dates for plotting\n",
        "train_dates = train_single.index.get_level_values('timestamp')\n",
        "# Get only the last pred_len dates for the test period\n",
        "test_dates = tsdf_single.index.get_level_values('timestamp')[-pred_len:]\n",
        "train_values = train_single['target'].values\n",
        "\n",
        "# Plot training data\n",
        "ax.plot(train_dates, train_values, 'b-', linewidth=1.5, label='Training Data')\n",
        "\n",
        "# Plot actual vs forecast\n",
        "ax.plot(test_dates, y_test, 'g-', linewidth=2, marker='o', markersize=8, label='Actual')\n",
        "ax.plot(test_dates, y_pred, 'r--', linewidth=2, marker='s', markersize=8, label='Forecast')\n",
        "\n",
        "# Highlight forecast region\n",
        "ax.axvspan(test_dates[0], test_dates[-1], alpha=0.1, color='yellow', label='Forecast Horizon')\n",
        "\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Demand (Units)')\n",
        "ax.set_title(f'Demand Forecast - {series_info[\"category\"]} ({series_info[\"region\"]}) | MAPE: {mape:.1f}%')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Forecast with Uncertainty Quantification\n",
        "\n",
        "TabPFN can provide prediction intervals, which is crucial for inventory planning to ensure adequate safety stock."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if prediction contains quantiles\n",
        "pred_columns = pred_single.columns.tolist()\n",
        "print(f\"Prediction columns: {pred_columns}\")\n",
        "\n",
        "# Extract prediction intervals if available\n",
        "if 'q0.05' in pred_columns and 'q0.95' in pred_columns:\n",
        "    y_lower = pred_single['q0.05'].values\n",
        "    y_upper = pred_single['q0.95'].values\n",
        "    y_median = pred_single['q0.5'].values if 'q0.5' in pred_columns else y_pred\n",
        "    \n",
        "    # Calculate coverage\n",
        "    coverage = np.mean((y_test >= y_lower) & (y_test <= y_upper))\n",
        "    print(f\"90% Prediction Interval Coverage: {coverage:.1%}\")\n",
        "else:\n",
        "    print(\"Quantile predictions not available in output. Using point predictions only.\")\n",
        "    y_lower = y_pred * 0.9  # Simple estimate\n",
        "    y_upper = y_pred * 1.1\n",
        "    y_median = y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize forecast with uncertainty\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "# Training data\n",
        "ax.plot(train_dates, train_values, 'b-', linewidth=1.5, label='Training Data', alpha=0.7)\n",
        "\n",
        "# Forecast with uncertainty band\n",
        "ax.fill_between(test_dates, y_lower, y_upper, alpha=0.3, color='red', label='90% Prediction Interval')\n",
        "ax.plot(test_dates, y_median, 'r-', linewidth=2, label='Forecast (Median)')\n",
        "ax.scatter(test_dates, y_test, color='green', s=100, zorder=5, label='Actual', edgecolors='black')\n",
        "\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Demand (Units)')\n",
        "ax.set_title(f'Demand Forecast with Uncertainty - {series_info[\"category\"]}')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Batch Forecasting Across Multiple Series\n",
        "\n",
        "In practice, demand planners need to forecast hundreds or thousands of SKU-location combinations. Let's demonstrate batch forecasting using the full TimeSeriesDataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Forecast multiple series\n",
        "n_series_to_forecast = 10  # Forecast 10 series for demonstration\n",
        "series_ids = tsdf.item_ids[:n_series_to_forecast]\n",
        "\n",
        "# Filter to selected series\n",
        "tsdf_subset = tsdf[tsdf.index.get_level_values('item_id').isin(series_ids)]\n",
        "\n",
        "# Define forecast horizon\n",
        "forecast_horizon = 6\n",
        "\n",
        "# Split all series\n",
        "train_batch, test_batch = tsdf_subset.train_test_split(prediction_length=forecast_horizon)\n",
        "test_X_batch = generate_test_X(train_batch, forecast_horizon)\n",
        "\n",
        "# Apply feature transformation\n",
        "train_batch_feat, test_X_batch_feat = transformer.transform(train_batch, test_X_batch)\n",
        "\n",
        "print(f\"Forecasting {len(series_ids)} series with {forecast_horizon}-month horizon...\")\n",
        "print(f\"Training samples: {len(train_batch_feat)}\")\n",
        "print(f\"Test samples: {len(test_X_batch_feat)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize predictor and make batch predictions\n",
        "predictor_batch = TabPFNTimeSeriesPredictor(tabpfn_mode=TabPFNMode.CLIENT)\n",
        "\n",
        "print(\"Generating batch forecasts...\")\n",
        "pred_batch = predictor_batch.predict(train_batch_feat, test_X_batch_feat)\n",
        "\n",
        "print(f\"Batch predictions shape: {pred_batch.shape}\")\n",
        "display(pred_batch.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate metrics for each series\n",
        "results = []\n",
        "\n",
        "for sid in series_ids:\n",
        "    # Get actual values from the original series (last forecast_horizon values)\n",
        "    # Note: test_batch from train_test_split returns the full series, not just the test portion\n",
        "    y_actual = tsdf_subset[tsdf_subset.index.get_level_values('item_id') == sid]['target'].values[-forecast_horizon:]\n",
        "    \n",
        "    # Get predictions\n",
        "    pred_col = 'mean' if 'mean' in pred_batch.columns else pred_batch.columns[0]\n",
        "    y_forecast = pred_batch[pred_batch.index.get_level_values('item_id') == sid][pred_col].values\n",
        "    \n",
        "    # Ensure arrays have same length (should both be forecast_horizon)\n",
        "    min_len = min(len(y_actual), len(y_forecast))\n",
        "    y_actual = y_actual[:min_len]\n",
        "    y_forecast = y_forecast[:min_len]\n",
        "    \n",
        "    # Calculate metrics\n",
        "    mae_s = mean_absolute_error(y_actual, y_forecast)\n",
        "    mape_s = np.mean(np.abs((y_actual - y_forecast) / (y_actual + 1e-8))) * 100\n",
        "    rmse_s = np.sqrt(mean_squared_error(y_actual, y_forecast))\n",
        "    \n",
        "    # Get series metadata\n",
        "    series_meta = df_demand[df_demand['series_id'] == sid].iloc[0]\n",
        "    \n",
        "    # Log to MLflow\n",
        "    with mlflow.start_run(run_name=f\"demand_forecast_{sid}\"):\n",
        "        mlflow.log_param(\"model_type\", \"TabPFNTimeSeriesPredictor\")\n",
        "        mlflow.log_param(\"tabpfn_mode\", \"CLIENT\")\n",
        "        mlflow.log_param(\"task\", \"demand_forecasting\")\n",
        "        mlflow.log_param(\"evaluation_type\", \"batch_forecasting\")\n",
        "        mlflow.log_param(\"series_id\", sid)\n",
        "        mlflow.log_param(\"category\", series_meta['category'])\n",
        "        mlflow.log_param(\"region\", series_meta['region'])\n",
        "        mlflow.log_param(\"forecast_horizon\", forecast_horizon)\n",
        "        \n",
        "        mlflow.log_metric(\"mae\", mae_s)\n",
        "        mlflow.log_metric(\"mape\", mape_s)\n",
        "        mlflow.log_metric(\"rmse\", rmse_s)\n",
        "        mlflow.log_metric(\"actual_total\", y_actual.sum())\n",
        "        mlflow.log_metric(\"forecast_total\", y_forecast.sum())\n",
        "    \n",
        "    results.append({\n",
        "        'series_id': sid,\n",
        "        'category': series_meta['category'],\n",
        "        'region': series_meta['region'],\n",
        "        'MAE': mae_s,\n",
        "        'MAPE': mape_s,\n",
        "        'actual_total': y_actual.sum(),\n",
        "        'forecast_total': y_forecast.sum()\n",
        "    })\n",
        "    print(f\"{sid}: {series_meta['category']:15s} | MAE={mae_s:,.0f}, MAPE={mape_s:.1f}%\")\n",
        "\n",
        "df_results = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary statistics with MLflow logging\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FORECAST ACCURACY SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nOverall Performance:\")\n",
        "print(f\"  Average MAPE: {df_results['MAPE'].mean():.1f}%\")\n",
        "print(f\"  Median MAPE: {df_results['MAPE'].median():.1f}%\")\n",
        "print(f\"  Best MAPE: {df_results['MAPE'].min():.1f}%\")\n",
        "print(f\"  Worst MAPE: {df_results['MAPE'].max():.1f}%\")\n",
        "\n",
        "# Log summary metrics to MLflow\n",
        "with mlflow.start_run(run_name=\"demand_forecast_batch_summary\"):\n",
        "    mlflow.log_param(\"model_type\", \"TabPFNTimeSeriesPredictor\")\n",
        "    mlflow.log_param(\"tabpfn_mode\", \"CLIENT\")\n",
        "    mlflow.log_param(\"task\", \"demand_forecasting\")\n",
        "    mlflow.log_param(\"evaluation_type\", \"batch_summary\")\n",
        "    mlflow.log_param(\"n_series\", n_series_to_forecast)\n",
        "    mlflow.log_param(\"forecast_horizon\", forecast_horizon)\n",
        "    \n",
        "    mlflow.log_metric(\"mape_mean\", df_results['MAPE'].mean())\n",
        "    mlflow.log_metric(\"mape_median\", df_results['MAPE'].median())\n",
        "    mlflow.log_metric(\"mape_min\", df_results['MAPE'].min())\n",
        "    mlflow.log_metric(\"mape_max\", df_results['MAPE'].max())\n",
        "    mlflow.log_metric(\"mae_mean\", df_results['MAE'].mean())\n",
        "    \n",
        "    print(f\"\\n  MLflow Summary Run ID: {mlflow.active_run().info.run_id}\")\n",
        "\n",
        "print(f\"\\nPerformance by Category:\")\n",
        "category_summary = df_results.groupby('category').agg({\n",
        "    'MAPE': 'mean',\n",
        "    'series_id': 'count'\n",
        "}).rename(columns={'series_id': 'n_series'})\n",
        "print(category_summary.round(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize MAPE distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# MAPE histogram\n",
        "axes[0].hist(df_results['MAPE'], bins=15, edgecolor='black', alpha=0.7)\n",
        "axes[0].axvline(df_results['MAPE'].mean(), color='red', linestyle='--', \n",
        "                label=f\"Mean: {df_results['MAPE'].mean():.1f}%\")\n",
        "axes[0].set_xlabel('MAPE (%)')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "axes[0].set_title('Distribution of Forecast Accuracy (MAPE)')\n",
        "axes[0].legend()\n",
        "\n",
        "# Actual vs Forecast scatter\n",
        "axes[1].scatter(df_results['actual_total'], df_results['forecast_total'], \n",
        "                alpha=0.7, s=100, c=df_results['category'].astype('category').cat.codes)\n",
        "max_val = max(df_results['actual_total'].max(), df_results['forecast_total'].max())\n",
        "axes[1].plot([0, max_val], [0, max_val], 'r--', label='Perfect Forecast')\n",
        "axes[1].set_xlabel('Actual Total Demand')\n",
        "axes[1].set_ylabel('Forecast Total Demand')\n",
        "axes[1].set_title(f'Forecast vs Actual ({forecast_horizon}-month total)')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Aggregate Forecasts for Planning\n",
        "\n",
        "Demand planners often need aggregated forecasts at different levels (category, region, total) for different planning decisions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggregate forecasts by category\n",
        "print(\"Aggregate Forecast Summary by Category:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "category_forecast = df_results.groupby('category').agg({\n",
        "    'actual_total': 'sum',\n",
        "    'forecast_total': 'sum',\n",
        "    'series_id': 'count'\n",
        "}).rename(columns={'series_id': 'n_series'})\n",
        "\n",
        "category_forecast['forecast_error'] = category_forecast['forecast_total'] - category_forecast['actual_total']\n",
        "category_forecast['error_pct'] = (category_forecast['forecast_error'] / category_forecast['actual_total']) * 100\n",
        "\n",
        "print(category_forecast.round(0))\n",
        "\n",
        "# Total company forecast\n",
        "total_actual = df_results['actual_total'].sum()\n",
        "total_forecast = df_results['forecast_total'].sum()\n",
        "total_error_pct = ((total_forecast - total_actual) / total_actual) * 100\n",
        "\n",
        "print(f\"\\nTotal Company Forecast:\")\n",
        "print(f\"  Actual: {total_actual:,.0f} units\")\n",
        "print(f\"  Forecast: {total_forecast:,.0f} units\")\n",
        "print(f\"  Error: {total_error_pct:+.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, we demonstrated:\n",
        "\n",
        "- **TimeSeriesDataFrame** - Native time series data structure for TabPFN\n",
        "- **FeatureTransformer** - Automatic feature engineering with calendar and seasonal features\n",
        "- **TabPFNTimeSeriesPredictor** - The foundation model for time series forecasting\n",
        "- **Single Series Forecasting** - End-to-end workflow for one series\n",
        "- **Uncertainty Quantification** - Prediction intervals for risk assessment\n",
        "- **Batch Forecasting** - Forecasting multiple series efficiently\n",
        "- **Aggregate Analysis** - Rolling up forecasts for planning\n",
        "\n",
        "**Key Takeaways:**\n",
        "1. TabPFN Time Series provides a dedicated API for time series forecasting\n",
        "2. Automatic feature engineering reduces manual preprocessing\n",
        "3. Built-in uncertainty quantification enables risk-aware planning\n",
        "4. Batch forecasting allows scaling to enterprise-level SKU counts\n",
        "\n",
        "**Typical Demand Planning MAPE Benchmarks:**\n",
        "- Excellent: < 15%\n",
        "- Good: 15-25%\n",
        "- Acceptable: 25-35%\n",
        "- Needs Improvement: > 35%\n",
        "\n",
        "**Next Steps:**\n",
        "- Integrate forecasts with inventory planning systems\n",
        "- Add external features (promotions, holidays, weather)\n",
        "- Implement hierarchical forecast reconciliation\n",
        "- Deploy as a scheduled Databricks workflow"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
