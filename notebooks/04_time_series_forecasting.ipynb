{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Demand Forecasting with TabPFN\n",
        "\n",
        "This notebook demonstrates time series forecasting for demand planning using TabPFN's regression capabilities.\n",
        "\n",
        "**Use Case:** Demand Planning - Forecast product demand by category and region\n",
        "\n",
        "**Business Context:** Accurate demand forecasting is the foundation of supply chain planning. It drives:\n",
        "- Inventory planning and safety stock optimization\n",
        "- Production scheduling and capacity planning\n",
        "- Distribution requirements planning (DRP)\n",
        "- Procurement and supplier management\n",
        "\n",
        "**What you will learn:**\n",
        "- How to prepare time series data with lag features\n",
        "- How to use TabPFN for time series forecasting\n",
        "- How to evaluate forecast accuracy with industry-standard metrics\n",
        "- How to forecast across multiple series and aggregate for planning\n",
        "\n",
        "**Prerequisites:** Run `00_data_preparation` notebook first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute Setup\n",
        "\n",
        "We recommend running this notebook on **Serverless Compute** with the **Base Environment V4**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install tabpfn-client scikit-learn pandas matplotlib --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dbutils.library.restartPython()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Authentication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tabpfn_client\n",
        "\n",
        "token = dbutils.secrets.get(scope=\"tabpfn-client\", key=\"token\")\n",
        "tabpfn_client.set_access_token(token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CATALOG = \"tabpfn_databricks\"\n",
        "SCHEMA = \"default\"\n",
        "\n",
        "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
        "spark.sql(f\"USE SCHEMA {SCHEMA}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from tabpfn_client import TabPFNRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Load Demand Forecast Data\n",
        "\n",
        "The demand forecast dataset contains monthly demand data across:\n",
        "- Multiple product categories (Beverages, Snacks, Dairy, Frozen, Personal Care)\n",
        "- Multiple regions (Northeast, Southeast, Midwest, West)\n",
        "\n",
        "Each series exhibits realistic patterns including:\n",
        "- Seasonality (annual patterns)\n",
        "- Trend (growth or decline)\n",
        "- Holiday effects\n",
        "- Random noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load demand forecast data\n",
        "df_demand = spark.table(\"demand_forecast\").toPandas()\n",
        "df_demand['date'] = pd.to_datetime(df_demand['date'])\n",
        "\n",
        "print(f\"Dataset shape: {df_demand.shape}\")\n",
        "print(f\"Number of time series: {df_demand['series_id'].nunique()}\")\n",
        "print(f\"Time range: {df_demand['date'].min().strftime('%Y-%m')} to {df_demand['date'].max().strftime('%Y-%m')}\")\n",
        "print(f\"\\nCategory distribution:\")\n",
        "print(df_demand['category'].value_counts())\n",
        "\n",
        "display(df_demand.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize sample time series\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Get one series from each category\n",
        "categories = df_demand['category'].unique()[:4]\n",
        "\n",
        "for ax, cat in zip(axes.flatten(), categories):\n",
        "    series_id = df_demand[df_demand['category'] == cat]['series_id'].iloc[0]\n",
        "    df_s = df_demand[df_demand['series_id'] == series_id].sort_values('date')\n",
        "    \n",
        "    ax.plot(df_s['date'], df_s['demand_units'], 'b-', linewidth=1.5, marker='o', markersize=3)\n",
        "    ax.set_title(f'{cat} ({df_s[\"region\"].iloc[0]})')\n",
        "    ax.set_xlabel('Date')\n",
        "    ax.set_ylabel('Demand (Units)')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Create Lag Features for Time Series Forecasting\n",
        "\n",
        "To use TabPFN for time series forecasting, we convert the time series problem into a supervised learning problem by creating lag features.\n",
        "\n",
        "For each time point, we use the previous N months as features to predict the current month's demand."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_lag_features(series, n_lags=12):\n",
        "    \"\"\"\n",
        "    Create lag features for time series forecasting.\n",
        "    \n",
        "    Args:\n",
        "        series: 1D array of time series values\n",
        "        n_lags: Number of lag features (months of history)\n",
        "    \n",
        "    Returns:\n",
        "        X: Feature matrix of shape (n_samples, n_lags)\n",
        "        y: Target array of shape (n_samples,)\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "    for i in range(n_lags, len(series)):\n",
        "        X.append(series[i-n_lags:i])\n",
        "        y.append(series[i])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "def add_calendar_features(X, dates, n_lags):\n",
        "    \"\"\"\n",
        "    Add calendar features (month, year) to lag features.\n",
        "    \"\"\"\n",
        "    # Convert numpy datetime64 to pandas Timestamp to access month/year\n",
        "    dates_subset = pd.to_datetime(dates[n_lags:])\n",
        "    months = np.array([d.month for d in dates_subset])\n",
        "    years = np.array([d.year for d in dates_subset])\n",
        "    \n",
        "    # Cyclical encoding for month\n",
        "    month_sin = np.sin(2 * np.pi * months / 12)\n",
        "    month_cos = np.cos(2 * np.pi * months / 12)\n",
        "    \n",
        "    X_enhanced = np.column_stack([X, month_sin, month_cos, years - years.min()])\n",
        "    return X_enhanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select a single series for detailed demonstration\n",
        "series_id = df_demand['series_id'].unique()[0]\n",
        "df_series = df_demand[df_demand['series_id'] == series_id].sort_values('date').reset_index(drop=True)\n",
        "\n",
        "values = df_series['demand_units'].values\n",
        "dates = df_series['date'].values\n",
        "\n",
        "print(f\"Selected series: {series_id}\")\n",
        "print(f\"Category: {df_series['category'].iloc[0]}\")\n",
        "print(f\"Region: {df_series['region'].iloc[0]}\")\n",
        "print(f\"Series length: {len(values)} months\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create lag features\n",
        "n_lags = 12  # Use last 12 months as features\n",
        "X, y = create_lag_features(values, n_lags)\n",
        "\n",
        "# Add calendar features\n",
        "X_enhanced = add_calendar_features(X, dates, n_lags)\n",
        "\n",
        "print(f\"Feature matrix shape: {X_enhanced.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "print(f\"\\nFeatures: {n_lags} lags + month_sin + month_cos + year_offset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Train-Test Split (Time-based)\n",
        "\n",
        "For time series, we use a time-based split to respect temporal ordering:\n",
        "- Training: Historical data\n",
        "- Test: Most recent periods (simulating forecast horizon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use last 6 months as test set (forecast horizon)\n",
        "test_size = 6\n",
        "\n",
        "X_train, X_test = X_enhanced[:-test_size], X_enhanced[-test_size:]\n",
        "y_train, y_test = y[:-test_size], y[-test_size:]\n",
        "\n",
        "# Get test dates for visualization\n",
        "test_dates = dates[n_lags:][-test_size:]\n",
        "\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Test samples: {len(X_test)} (forecast horizon: {test_size} months)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Train TabPFN Forecaster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train TabPFN regressor\n",
        "reg = TabPFNRegressor()\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = reg.predict(X_test)\n",
        "\n",
        "# Calculate forecast metrics\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "# Calculate bias\n",
        "bias = np.mean(y_pred - y_test)\n",
        "bias_pct = (bias / np.mean(y_test)) * 100\n",
        "\n",
        "print(f\"Forecast Metrics ({test_size}-month horizon):\")\n",
        "print(f\"  MAE:  {mae:,.0f} units\")\n",
        "print(f\"  RMSE: {rmse:,.0f} units\")\n",
        "print(f\"  MAPE: {mape:.1f}%\")\n",
        "print(f\"  Bias: {bias:,.0f} units ({bias_pct:+.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize forecast\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "# Full series\n",
        "all_dates = dates[n_lags:]\n",
        "ax.plot(all_dates[:-test_size], y_train, 'b-', linewidth=1.5, label='Training Data')\n",
        "\n",
        "# Actual vs Forecast\n",
        "ax.plot(test_dates, y_test, 'g-', linewidth=2, marker='o', markersize=8, label='Actual')\n",
        "ax.plot(test_dates, y_pred, 'r--', linewidth=2, marker='s', markersize=8, label='Forecast')\n",
        "\n",
        "# Highlight forecast region\n",
        "ax.axvspan(test_dates[0], test_dates[-1], alpha=0.1, color='yellow', label='Forecast Horizon')\n",
        "\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Demand (Units)')\n",
        "ax.set_title(f'Demand Forecast - {df_series[\"category\"].iloc[0]} ({df_series[\"region\"].iloc[0]}) | MAPE: {mape:.1f}%')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Forecast with Uncertainty Quantification\n",
        "\n",
        "TabPFN can provide prediction intervals, which is crucial for inventory planning to ensure adequate safety stock."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get predictions with uncertainty (quantiles for 90% prediction interval)\n",
        "y_lower = reg.predict(X_test, output_type=\"quantiles\", quantiles=[0.05]).flatten()\n",
        "y_median = reg.predict(X_test, output_type=\"quantiles\", quantiles=[0.5]).flatten()\n",
        "y_upper = reg.predict(X_test, output_type=\"quantiles\", quantiles=[0.95]).flatten()\n",
        "\n",
        "# Calculate coverage\n",
        "coverage = np.mean((y_test >= y_lower) & (y_test <= y_upper))\n",
        "print(f\"90% Prediction Interval Coverage: {coverage:.1%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize forecast with uncertainty\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "# Training data\n",
        "ax.plot(all_dates[:-test_size], y_train, 'b-', linewidth=1.5, label='Training Data', alpha=0.7)\n",
        "\n",
        "# Forecast with uncertainty band\n",
        "ax.fill_between(test_dates, y_lower, y_upper, alpha=0.3, color='red', label='90% Prediction Interval')\n",
        "ax.plot(test_dates, y_median, 'r-', linewidth=2, label='Forecast (Median)')\n",
        "ax.scatter(test_dates, y_test, color='green', s=100, zorder=5, label='Actual', edgecolors='black')\n",
        "\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Demand (Units)')\n",
        "ax.set_title(f'Demand Forecast with Uncertainty - {df_series[\"category\"].iloc[0]}')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Batch Forecasting Across Multiple Series\n",
        "\n",
        "In practice, demand planners need to forecast hundreds or thousands of SKU-location combinations. Let's demonstrate batch forecasting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Forecast multiple series\n",
        "n_series_to_forecast = 10  # Forecast 10 series for demonstration\n",
        "series_ids = df_demand['series_id'].unique()[:n_series_to_forecast]\n",
        "\n",
        "results = []\n",
        "forecast_horizon = 6\n",
        "\n",
        "print(f\"Forecasting {len(series_ids)} series with {forecast_horizon}-month horizon...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for sid in series_ids:\n",
        "    df_s = df_demand[df_demand['series_id'] == sid].sort_values('date')\n",
        "    vals = df_s['demand_units'].values\n",
        "    dts = df_s['date'].values\n",
        "    \n",
        "    # Create features\n",
        "    X_s, y_s = create_lag_features(vals, n_lags)\n",
        "    X_s_enh = add_calendar_features(X_s, dts, n_lags)\n",
        "    \n",
        "    # Split\n",
        "    X_tr, X_te = X_s_enh[:-forecast_horizon], X_s_enh[-forecast_horizon:]\n",
        "    y_tr, y_te = y_s[:-forecast_horizon], y_s[-forecast_horizon:]\n",
        "    \n",
        "    # Train and predict\n",
        "    model = TabPFNRegressor()\n",
        "    model.fit(X_tr, y_tr)\n",
        "    pred = model.predict(X_te)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    mae_s = mean_absolute_error(y_te, pred)\n",
        "    mape_s = np.mean(np.abs((y_te - pred) / y_te)) * 100\n",
        "    \n",
        "    results.append({\n",
        "        'series_id': sid,\n",
        "        'category': df_s['category'].iloc[0],\n",
        "        'region': df_s['region'].iloc[0],\n",
        "        'MAE': mae_s,\n",
        "        'MAPE': mape_s,\n",
        "        'actual_total': y_te.sum(),\n",
        "        'forecast_total': pred.sum()\n",
        "    })\n",
        "    print(f\"{sid}: {df_s['category'].iloc[0]:15s} | MAE={mae_s:,.0f}, MAPE={mape_s:.1f}%\")\n",
        "\n",
        "df_results = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary statistics\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FORECAST ACCURACY SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nOverall Performance:\")\n",
        "print(f\"  Average MAPE: {df_results['MAPE'].mean():.1f}%\")\n",
        "print(f\"  Median MAPE: {df_results['MAPE'].median():.1f}%\")\n",
        "print(f\"  Best MAPE: {df_results['MAPE'].min():.1f}%\")\n",
        "print(f\"  Worst MAPE: {df_results['MAPE'].max():.1f}%\")\n",
        "\n",
        "print(f\"\\nPerformance by Category:\")\n",
        "category_summary = df_results.groupby('category').agg({\n",
        "    'MAPE': 'mean',\n",
        "    'series_id': 'count'\n",
        "}).rename(columns={'series_id': 'n_series'})\n",
        "print(category_summary.round(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize MAPE distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# MAPE histogram\n",
        "axes[0].hist(df_results['MAPE'], bins=15, edgecolor='black', alpha=0.7)\n",
        "axes[0].axvline(df_results['MAPE'].mean(), color='red', linestyle='--', \n",
        "                label=f\"Mean: {df_results['MAPE'].mean():.1f}%\")\n",
        "axes[0].set_xlabel('MAPE (%)')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "axes[0].set_title('Distribution of Forecast Accuracy (MAPE)')\n",
        "axes[0].legend()\n",
        "\n",
        "# Actual vs Forecast scatter\n",
        "axes[1].scatter(df_results['actual_total'], df_results['forecast_total'], \n",
        "                alpha=0.7, s=100, c=df_results['category'].astype('category').cat.codes)\n",
        "max_val = max(df_results['actual_total'].max(), df_results['forecast_total'].max())\n",
        "axes[1].plot([0, max_val], [0, max_val], 'r--', label='Perfect Forecast')\n",
        "axes[1].set_xlabel('Actual Total Demand')\n",
        "axes[1].set_ylabel('Forecast Total Demand')\n",
        "axes[1].set_title(f'Forecast vs Actual ({forecast_horizon}-month total)')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Aggregate Forecasts for Planning\n",
        "\n",
        "Demand planners often need aggregated forecasts at different levels (category, region, total) for different planning decisions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggregate forecasts by category\n",
        "print(\"Aggregate Forecast Summary by Category:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "category_forecast = df_results.groupby('category').agg({\n",
        "    'actual_total': 'sum',\n",
        "    'forecast_total': 'sum',\n",
        "    'series_id': 'count'\n",
        "}).rename(columns={'series_id': 'n_series'})\n",
        "\n",
        "category_forecast['forecast_error'] = category_forecast['forecast_total'] - category_forecast['actual_total']\n",
        "category_forecast['error_pct'] = (category_forecast['forecast_error'] / category_forecast['actual_total']) * 100\n",
        "\n",
        "print(category_forecast.round(0))\n",
        "\n",
        "# Total company forecast\n",
        "total_actual = df_results['actual_total'].sum()\n",
        "total_forecast = df_results['forecast_total'].sum()\n",
        "total_error_pct = ((total_forecast - total_actual) / total_actual) * 100\n",
        "\n",
        "print(f\"\\nTotal Company Forecast:\")\n",
        "print(f\"  Actual: {total_actual:,.0f} units\")\n",
        "print(f\"  Forecast: {total_forecast:,.0f} units\")\n",
        "print(f\"  Error: {total_error_pct:+.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Business Application: Safety Stock Calculation\n",
        "\n",
        "The uncertainty quantification from TabPFN can be used to calculate safety stock levels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate safety stock based on forecast uncertainty\n",
        "# Using the first series as an example\n",
        "\n",
        "df_s = df_demand[df_demand['series_id'] == series_ids[0]].sort_values('date')\n",
        "vals = df_s['demand_units'].values\n",
        "dts = df_s['date'].values\n",
        "\n",
        "X_s, y_s = create_lag_features(vals, n_lags)\n",
        "X_s_enh = add_calendar_features(X_s, dts, n_lags)\n",
        "\n",
        "X_tr, X_te = X_s_enh[:-forecast_horizon], X_s_enh[-forecast_horizon:]\n",
        "y_tr, y_te = y_s[:-forecast_horizon], y_s[-forecast_horizon:]\n",
        "\n",
        "model = TabPFNRegressor()\n",
        "model.fit(X_tr, y_tr)\n",
        "\n",
        "# Get prediction intervals\n",
        "p50 = model.predict(X_te, output_type=\"quantiles\", quantiles=[0.5]).flatten()\n",
        "p95 = model.predict(X_te, output_type=\"quantiles\", quantiles=[0.95]).flatten()\n",
        "\n",
        "# Safety stock = P95 - P50 (covers upside demand risk)\n",
        "safety_stock = p95 - p50\n",
        "\n",
        "print(\"Safety Stock Calculation (95% service level):\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nSeries: {series_ids[0]}\")\n",
        "print(f\"Category: {df_s['category'].iloc[0]}\")\n",
        "\n",
        "ss_df = pd.DataFrame({\n",
        "    'Month': range(1, forecast_horizon + 1),\n",
        "    'Forecast (P50)': p50.round(0).astype(int),\n",
        "    'Upside (P95)': p95.round(0).astype(int),\n",
        "    'Safety Stock': safety_stock.round(0).astype(int)\n",
        "})\n",
        "display(ss_df)\n",
        "\n",
        "print(f\"\\nTotal Safety Stock Required: {safety_stock.sum():,.0f} units\")\n",
        "print(f\"Safety Stock as % of Forecast: {(safety_stock.sum() / p50.sum()) * 100:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, we demonstrated:\n",
        "\n",
        "- ✅ **Time Series Feature Engineering** - Creating lag and calendar features\n",
        "- ✅ **Single Series Forecasting** - Training TabPFN on historical demand\n",
        "- ✅ **Uncertainty Quantification** - Prediction intervals for risk assessment\n",
        "- ✅ **Batch Forecasting** - Forecasting multiple series efficiently\n",
        "- ✅ **Aggregate Analysis** - Rolling up forecasts for planning\n",
        "- ✅ **Safety Stock Calculation** - Using uncertainty for inventory planning\n",
        "\n",
        "**Key Takeaways:**\n",
        "1. TabPFN can be effectively used for time series forecasting with lag features\n",
        "2. Built-in uncertainty quantification enables safety stock optimization\n",
        "3. Batch forecasting allows scaling to enterprise-level SKU counts\n",
        "\n",
        "**Typical Demand Planning MAPE Benchmarks:**\n",
        "- Excellent: < 15%\n",
        "- Good: 15-25%\n",
        "- Acceptable: 25-35%\n",
        "- Needs Improvement: > 35%\n",
        "\n",
        "**Next Steps:**\n",
        "- Integrate forecasts with inventory planning systems\n",
        "- Add external features (promotions, holidays, weather)\n",
        "- Implement hierarchical forecast reconciliation\n",
        "- Deploy as a scheduled Databricks workflow"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
