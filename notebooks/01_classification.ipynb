{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Supply Chain Risk Classification with TabPFN\n",
        "\n",
        "This notebook demonstrates how to use **TabPFN** for classification tasks in retail/CPG supply chain planning.\n",
        "\n",
        "TabPFN is a foundation model for tabular data that outperforms traditional methods while being dramatically faster. It requires no hyperparameter tuning and works out-of-the-box.\n",
        "\n",
        "**Use Cases Covered:**\n",
        "1. **Supplier Delay Risk Prediction** (Binary Classification) - Predict which supplier deliveries will be delayed\n",
        "2. **Material Shortage Prediction** (Multi-class Classification) - Predict material shortage risk levels\n",
        "3. **Labor Shortage Prediction** (Multi-class Classification) - Predict workforce availability issues\n",
        "4. **OTIF Risk Prediction** (Multi-class Classification) - Predict on-time-in-full delivery risk\n",
        "\n",
        "**Business Value:**\n",
        "- Enable proactive supply risk mitigation\n",
        "- Optimize safety stock and expediting decisions\n",
        "- Improve workforce planning and scheduling\n",
        "- Improve on-time delivery performance\n",
        "- Enhance customer service through proactive OTIF management\n",
        "\n",
        "**Prerequisites:** Run `00_data_preparation` notebook first to set up the datasets.\n",
        "\n",
        "**References:**\n",
        "- [TabPFN Client GitHub](https://github.com/PriorLabs/tabpfn-client)\n",
        "- [Prior Labs Documentation](https://docs.priorlabs.ai/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute Setup\n",
        "\n",
        "We recommend running this notebook on **Serverless Compute** with the **Base Environment V4**.\n",
        "\n",
        "To configure:\n",
        "1. Click on the compute selector in the notebook toolbar\n",
        "2. Select **Serverless**\n",
        "3. Under Environment, choose **Base Environment V4**\n",
        "\n",
        "Serverless compute provides fast startup times and automatic scaling, ideal for interactive notebook workflows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install tabpfn-client scikit-learn pandas matplotlib mlflow --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dbutils.library.restartPython()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Authentication\n",
        "\n",
        "TabPFN client requires authentication using an access token.\n",
        "\n",
        "**Setting up Databricks Secrets (one-time setup):**\n",
        "\n",
        "1. Create a secret scope using the Databricks CLI:\n",
        "   ```bash\n",
        "   databricks secrets create-scope tabpfn-client\n",
        "   ```\n",
        "\n",
        "2. Store your TabPFN token in the secret scope:\n",
        "   ```bash\n",
        "   databricks secrets put-secret tabpfn-client token\n",
        "   ```\n",
        "\n",
        "3. You can retrieve your TabPFN token on another machine by running:\n",
        "   ```python\n",
        "   import tabpfn_client\n",
        "   token = tabpfn_client.get_access_token()\n",
        "   print(token)\n",
        "   ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tabpfn_client\n",
        "\n",
        "token = dbutils.secrets.get(scope=\"tabpfn-client\", key=\"token\")\n",
        "tabpfn_client.set_access_token(token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Configuration\n",
        "\n",
        "Configure the catalog and schema where the prepared datasets are stored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure catalog and schema (must match 00_data_preparation)\n",
        "CATALOG = \"tabpfn_databricks\"\n",
        "SCHEMA = \"default\"\n",
        "\n",
        "# MLflow experiment configuration (shared across all TabPFN notebooks)\n",
        "# Default uses user namespace, but can be customized\n",
        "current_user = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
        "MLFLOW_EXPERIMENT_NAME = f\"/Users/{current_user}/tabpfn-databricks\"\n",
        "\n",
        "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
        "spark.sql(f\"USE SCHEMA {SCHEMA}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import mlflow\n",
        "\n",
        "from tabpfn_client import TabPFNClassifier\n",
        "\n",
        "# Set MLflow experiment\n",
        "mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)\n",
        "print(f\"MLflow experiment set to: {MLFLOW_EXPERIMENT_NAME}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 1: Supply Planning\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Supplier Delay Risk Prediction (Binary Classification)\n",
        "\n",
        "**Business Context:** Supply planners need to identify which incoming supplier deliveries are at risk of delay so they can:\n",
        "- Expedite high-risk orders\n",
        "- Adjust production schedules\n",
        "- Communicate proactively with stakeholders\n",
        "\n",
        "We'll use TabPFN to predict whether a supplier delivery will be delayed based on:\n",
        "- Supplier characteristics (tier, country, reliability history)\n",
        "- Order characteristics (quantity, value, lead time)\n",
        "- External factors (port congestion, weather risk, peak season)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the Supplier Delay Risk training dataset from Delta table\n",
        "df_delay = spark.table(\"supplier_delay_risk_train\").toPandas()\n",
        "\n",
        "print(f\"Dataset shape: {df_delay.shape}\")\n",
        "print(f\"\\nFeatures:\")\n",
        "print([col for col in df_delay.columns if col != 'is_delayed'])\n",
        "print(f\"\\nTarget distribution (is_delayed):\")\n",
        "print(f\"  On-time (0): {(df_delay['is_delayed'] == 0).sum()}\")\n",
        "print(f\"  Delayed (1): {(df_delay['is_delayed'] == 1).sum()}\")\n",
        "print(f\"  Delay rate: {df_delay['is_delayed'].mean():.1%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features - encode categorical columns\n",
        "df_encoded = pd.get_dummies(df_delay, columns=['supplier_tier', 'supplier_country'], drop_first=True)\n",
        "\n",
        "# Separate features and target\n",
        "feature_cols = [col for col in df_encoded.columns if col != 'is_delayed']\n",
        "X = df_encoded[feature_cols].values\n",
        "y = df_delay['is_delayed'].values\n",
        "\n",
        "print(f\"Feature matrix shape: {X.shape}\")\n",
        "print(f\"Number of encoded features: {len(feature_cols)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {len(X_train)}\")\n",
        "print(f\"Test set size: {len(X_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize and train TabPFN classifier with MLflow logging\n",
        "with mlflow.start_run(run_name=\"supplier_delay_risk_tabpfn\"):\n",
        "    # Log parameters\n",
        "    mlflow.log_param(\"model_type\", \"TabPFNClassifier\")\n",
        "    mlflow.log_param(\"task\", \"supplier_delay_risk\")\n",
        "    mlflow.log_param(\"problem_type\", \"binary_classification\")\n",
        "    mlflow.log_param(\"test_size\", 0.2)\n",
        "    mlflow.log_param(\"n_features\", X_train.shape[1])\n",
        "    mlflow.log_param(\"train_samples\", X_train.shape[0])\n",
        "    mlflow.log_param(\"test_samples\", X_test.shape[0])\n",
        "    \n",
        "    clf = TabPFNClassifier()\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = clf.predict(X_test)\n",
        "    y_pred_proba = clf.predict_proba(X_test)\n",
        "\n",
        "    # Evaluate performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred_proba[:, 1])\n",
        "    \n",
        "    # Log metrics\n",
        "    mlflow.log_metric(\"accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
        "\n",
        "    print(f\"TabPFN Supplier Delay Risk Prediction Results:\")\n",
        "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"  ROC AUC:  {roc_auc:.4f}\")\n",
        "    print(f\"  MLflow Run ID: {mlflow.active_run().info.run_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detailed classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['On-Time', 'Delayed']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize high-risk deliveries\n",
        "# Show deliveries with highest predicted delay probability\n",
        "df_test = df_delay.iloc[X_train.shape[0]:].copy().reset_index(drop=True)\n",
        "df_test['delay_probability'] = y_pred_proba[:, 1]\n",
        "df_test['predicted_delayed'] = y_pred\n",
        "\n",
        "print(\"Top 10 Highest Risk Deliveries:\")\n",
        "high_risk = df_test.nlargest(10, 'delay_probability')[[\n",
        "    'supplier_tier', 'supplier_country', 'contracted_lead_time_days',\n",
        "    'historical_otd_rate', 'port_congestion_index', 'delay_probability', 'is_delayed'\n",
        "]]\n",
        "display(high_risk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Material Shortage Prediction (Multi-class Classification)\n",
        "\n",
        "**Business Context:** Material planners need to identify which materials are at risk of shortage to:\n",
        "- Prioritize procurement actions\n",
        "- Expedite critical orders\n",
        "- Adjust production schedules\n",
        "\n",
        "We'll predict shortage risk levels:\n",
        "- **0 = No Risk**: Adequate inventory coverage\n",
        "- **1 = At Risk**: Monitor closely, may need action\n",
        "- **2 = Critical**: Immediate action required"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the Material Shortage training dataset from Delta table\n",
        "df_shortage = spark.table(\"material_shortage_train\").toPandas()\n",
        "\n",
        "print(f\"Dataset shape: {df_shortage.shape}\")\n",
        "print(f\"\\nTarget distribution (shortage_risk):\")\n",
        "shortage_labels = {0: 'No Risk', 1: 'At Risk', 2: 'Critical'}\n",
        "for val, label in shortage_labels.items():\n",
        "    count = (df_shortage['shortage_risk'] == val).sum()\n",
        "    print(f\"  {val} ({label}): {count} ({count/len(df_shortage):.1%})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features - encode categorical columns\n",
        "df_shortage_encoded = pd.get_dummies(df_shortage, \n",
        "                                      columns=['material_type', 'criticality_class'], \n",
        "                                      drop_first=True)\n",
        "\n",
        "# Separate features and target\n",
        "shortage_feature_cols = [col for col in df_shortage_encoded.columns if col != 'shortage_risk']\n",
        "X_shortage = df_shortage_encoded[shortage_feature_cols].values\n",
        "y_shortage = df_shortage['shortage_risk'].values\n",
        "\n",
        "print(f\"Feature matrix shape: {X_shortage.shape}\")\n",
        "\n",
        "# Split the data\n",
        "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(\n",
        "    X_shortage, y_shortage, test_size=0.3, random_state=42, stratify=y_shortage\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train TabPFN on multi-class problem with MLflow logging\n",
        "with mlflow.start_run(run_name=\"material_shortage_tabpfn\"):\n",
        "    # Log parameters\n",
        "    mlflow.log_param(\"model_type\", \"TabPFNClassifier\")\n",
        "    mlflow.log_param(\"task\", \"material_shortage\")\n",
        "    mlflow.log_param(\"problem_type\", \"multiclass_classification\")\n",
        "    mlflow.log_param(\"n_classes\", 3)\n",
        "    mlflow.log_param(\"test_size\", 0.3)\n",
        "    mlflow.log_param(\"n_features\", X_train_s.shape[1])\n",
        "    mlflow.log_param(\"train_samples\", X_train_s.shape[0])\n",
        "    mlflow.log_param(\"test_samples\", X_test_s.shape[0])\n",
        "    \n",
        "    clf_shortage = TabPFNClassifier()\n",
        "    clf_shortage.fit(X_train_s, y_train_s)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred_shortage = clf_shortage.predict(X_test_s)\n",
        "    y_pred_proba_shortage = clf_shortage.predict_proba(X_test_s)\n",
        "\n",
        "    # Evaluate\n",
        "    accuracy_shortage = accuracy_score(y_test_s, y_pred_shortage)\n",
        "    \n",
        "    # Log metrics\n",
        "    mlflow.log_metric(\"accuracy\", accuracy_shortage)\n",
        "    \n",
        "    print(f\"Multi-class Classification Accuracy: {accuracy_shortage:.4f}\")\n",
        "    print(f\"MLflow Run ID: {mlflow.active_run().info.run_id}\")\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test_s, y_pred_shortage, \n",
        "                                target_names=['No Risk', 'At Risk', 'Critical']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test_s, y_pred_shortage)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "im = ax.imshow(cm, interpolation='nearest', cmap='Blues')\n",
        "ax.figure.colorbar(im, ax=ax)\n",
        "\n",
        "classes = ['No Risk', 'At Risk', 'Critical']\n",
        "ax.set(xticks=np.arange(cm.shape[1]),\n",
        "       yticks=np.arange(cm.shape[0]),\n",
        "       xticklabels=classes, yticklabels=classes,\n",
        "       title='Material Shortage Risk - Confusion Matrix',\n",
        "       ylabel='Actual',\n",
        "       xlabel='Predicted')\n",
        "\n",
        "# Add text annotations\n",
        "thresh = cm.max() / 2.\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        ax.text(j, i, format(cm[i, j], 'd'),\n",
        "                ha=\"center\", va=\"center\",\n",
        "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify critical materials requiring immediate attention\n",
        "df_test_shortage = df_shortage.iloc[X_train_s.shape[0]:].copy().reset_index(drop=True)\n",
        "df_test_shortage['predicted_risk'] = y_pred_shortage\n",
        "df_test_shortage['critical_probability'] = y_pred_proba_shortage[:, 2]  # Probability of Critical\n",
        "\n",
        "print(\"Top 10 Materials with Highest Critical Risk Probability:\")\n",
        "critical_materials = df_test_shortage.nlargest(10, 'critical_probability')[[\n",
        "    'material_type', 'criticality_class', 'current_stock_days',\n",
        "    'num_active_suppliers', 'avg_supplier_reliability', \n",
        "    'critical_probability', 'shortage_risk'\n",
        "]]\n",
        "display(critical_materials)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 2: Production Planning\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Labor Shortage Prediction (Multi-class Classification)\n",
        "\n",
        "**Business Context:** Production and HR planners need to anticipate workforce availability issues to:\n",
        "- Schedule overtime or temporary staffing\n",
        "- Adjust production schedules based on labor constraints\n",
        "- Prioritize cross-training initiatives\n",
        "- Improve hiring and retention strategies\n",
        "\n",
        "We'll predict labor shortage risk levels:\n",
        "- **0 = Adequate**: Sufficient workforce coverage\n",
        "- **1 = At Risk**: Monitor closely, may need contingency plans\n",
        "- **2 = Critical**: Immediate staffing action required"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the Labor Shortage training dataset from Delta table\n",
        "df_labor = spark.table(\"labor_shortage_train\").toPandas()\n",
        "\n",
        "print(f\"Dataset shape: {df_labor.shape}\")\n",
        "print(f\"\\nFeatures:\")\n",
        "print([col for col in df_labor.columns if col != 'labor_shortage_risk'])\n",
        "print(f\"\\nTarget distribution (labor_shortage_risk):\")\n",
        "labor_labels = {0: 'Adequate', 1: 'At Risk', 2: 'Critical'}\n",
        "for val, label in labor_labels.items():\n",
        "    count = (df_labor['labor_shortage_risk'] == val).sum()\n",
        "    print(f\"  {val} ({label}): {count} ({count/len(df_labor):.1%})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features - encode categorical columns\n",
        "df_labor_encoded = pd.get_dummies(df_labor, \n",
        "                                   columns=['facility_type', 'facility_size', 'region'], \n",
        "                                   drop_first=True)\n",
        "\n",
        "# Separate features and target\n",
        "labor_feature_cols = [col for col in df_labor_encoded.columns if col != 'labor_shortage_risk']\n",
        "X_labor = df_labor_encoded[labor_feature_cols].values\n",
        "y_labor = df_labor['labor_shortage_risk'].values\n",
        "\n",
        "print(f\"Feature matrix shape: {X_labor.shape}\")\n",
        "\n",
        "# Split the data\n",
        "X_train_l, X_test_l, y_train_l, y_test_l = train_test_split(\n",
        "    X_labor, y_labor, test_size=0.3, random_state=42, stratify=y_labor\n",
        ")\n",
        "print(f\"Training set size: {len(X_train_l)}\")\n",
        "print(f\"Test set size: {len(X_test_l)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train TabPFN on labor shortage prediction with MLflow logging\n",
        "with mlflow.start_run(run_name=\"labor_shortage_tabpfn\"):\n",
        "    # Log parameters\n",
        "    mlflow.log_param(\"model_type\", \"TabPFNClassifier\")\n",
        "    mlflow.log_param(\"task\", \"labor_shortage\")\n",
        "    mlflow.log_param(\"problem_type\", \"multiclass_classification\")\n",
        "    mlflow.log_param(\"n_classes\", 3)\n",
        "    mlflow.log_param(\"test_size\", 0.3)\n",
        "    mlflow.log_param(\"n_features\", X_train_l.shape[1])\n",
        "    mlflow.log_param(\"train_samples\", X_train_l.shape[0])\n",
        "    mlflow.log_param(\"test_samples\", X_test_l.shape[0])\n",
        "    \n",
        "    clf_labor = TabPFNClassifier()\n",
        "    clf_labor.fit(X_train_l, y_train_l)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred_labor = clf_labor.predict(X_test_l)\n",
        "    y_pred_proba_labor = clf_labor.predict_proba(X_test_l)\n",
        "\n",
        "    # Evaluate\n",
        "    accuracy_labor = accuracy_score(y_test_l, y_pred_labor)\n",
        "    \n",
        "    # Log metrics\n",
        "    mlflow.log_metric(\"accuracy\", accuracy_labor)\n",
        "\n",
        "    print(f\"Multi-class Classification Accuracy: {accuracy_labor:.4f}\")\n",
        "    print(f\"MLflow Run ID: {mlflow.active_run().info.run_id}\")\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test_l, y_pred_labor, \n",
        "                                target_names=['Adequate', 'At Risk', 'Critical']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion Matrix for Labor Shortage\n",
        "cm_labor = confusion_matrix(y_test_l, y_pred_labor)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "im = ax.imshow(cm_labor, interpolation='nearest', cmap='Oranges')\n",
        "ax.figure.colorbar(im, ax=ax)\n",
        "\n",
        "classes = ['Adequate', 'At Risk', 'Critical']\n",
        "ax.set(xticks=np.arange(cm_labor.shape[1]),\n",
        "       yticks=np.arange(cm_labor.shape[0]),\n",
        "       xticklabels=classes, yticklabels=classes,\n",
        "       title='Labor Shortage Risk - Confusion Matrix',\n",
        "       ylabel='Actual',\n",
        "       xlabel='Predicted')\n",
        "\n",
        "thresh = cm_labor.max() / 2.\n",
        "for i in range(cm_labor.shape[0]):\n",
        "    for j in range(cm_labor.shape[1]):\n",
        "        ax.text(j, i, format(cm_labor[i, j], 'd'),\n",
        "                ha=\"center\", va=\"center\",\n",
        "                color=\"white\" if cm_labor[i, j] > thresh else \"black\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify facilities with highest labor shortage risk\n",
        "df_test_labor = df_labor.iloc[X_train_l.shape[0]:].copy().reset_index(drop=True)\n",
        "df_test_labor['predicted_risk'] = y_pred_labor\n",
        "df_test_labor['critical_probability'] = y_pred_proba_labor[:, 2]  # Probability of Critical\n",
        "\n",
        "print(\"Top 10 Facilities with Highest Critical Labor Shortage Risk:\")\n",
        "critical_facilities = df_test_labor.nlargest(10, 'critical_probability')[[\n",
        "    'facility_type', 'region', 'current_headcount', 'headcount_ratio',\n",
        "    'turnover_rate_monthly', 'open_positions', 'local_unemployment_rate',\n",
        "    'critical_probability', 'labor_shortage_risk'\n",
        "]]\n",
        "display(critical_facilities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze risk by facility type and region\n",
        "df_test_labor['risk_label'] = df_test_labor['predicted_risk'].map({0: 'Adequate', 1: 'At Risk', 2: 'Critical'})\n",
        "\n",
        "print(\"\\nPredicted Labor Shortage Risk by Facility Type:\")\n",
        "display(pd.crosstab(df_test_labor['facility_type'], df_test_labor['risk_label'], normalize='index').round(3) * 100)\n",
        "\n",
        "print(\"\\nPredicted Labor Shortage Risk by Region:\")\n",
        "display(pd.crosstab(df_test_labor['region'], df_test_labor['risk_label'], normalize='index').round(3) * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 3: Distribution Planning\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. OTIF Risk Prediction (Multi-class Classification)\n",
        "\n",
        "**Business Context:** Distribution and customer service teams need to identify orders at risk of not being delivered On-Time-In-Full (OTIF) to:\n",
        "- Proactively communicate with customers about potential delays\n",
        "- Prioritize orders for expedited processing\n",
        "- Allocate resources to high-risk shipments\n",
        "- Improve overall customer satisfaction and retention\n",
        "\n",
        "We'll predict OTIF risk levels:\n",
        "- **0 = Low Risk**: High confidence of successful OTIF delivery\n",
        "- **1 = Medium Risk**: Monitor closely, may need intervention\n",
        "- **2 = High Risk**: Immediate action required to prevent OTIF failure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the OTIF Risk training dataset from Delta table\n",
        "df_otif = spark.table(\"otif_risk_train\").toPandas()\n",
        "\n",
        "print(f\"Dataset shape: {df_otif.shape}\")\n",
        "print(f\"\\nFeatures:\")\n",
        "print([col for col in df_otif.columns if col != 'otif_risk'])\n",
        "print(f\"\\nTarget distribution (otif_risk):\")\n",
        "otif_labels = {0: 'Low Risk', 1: 'Medium Risk', 2: 'High Risk'}\n",
        "for val, label in otif_labels.items():\n",
        "    count = (df_otif['otif_risk'] == val).sum()\n",
        "    print(f\"  {val} ({label}): {count} ({count/len(df_otif):.1%})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features - encode categorical columns\n",
        "df_otif_encoded = pd.get_dummies(df_otif, \n",
        "                                  columns=['order_type', 'order_size', 'customer_tier', \n",
        "                                          'customer_order_frequency', 'fulfillment_source',\n",
        "                                          'carrier_tier', 'order_day_of_week', \n",
        "                                          'requested_delivery_window'], \n",
        "                                  drop_first=True)\n",
        "\n",
        "# Separate features and target\n",
        "otif_feature_cols = [col for col in df_otif_encoded.columns if col != 'otif_risk']\n",
        "X_otif = df_otif_encoded[otif_feature_cols].values\n",
        "y_otif = df_otif['otif_risk'].values\n",
        "\n",
        "print(f\"Feature matrix shape: {X_otif.shape}\")\n",
        "\n",
        "# Split the data\n",
        "X_train_o, X_test_o, y_train_o, y_test_o = train_test_split(\n",
        "    X_otif, y_otif, test_size=0.3, random_state=42, stratify=y_otif\n",
        ")\n",
        "print(f\"Training set size: {len(X_train_o)}\")\n",
        "print(f\"Test set size: {len(X_test_o)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train TabPFN on OTIF risk prediction with MLflow logging\n",
        "with mlflow.start_run(run_name=\"otif_risk_tabpfn\"):\n",
        "    # Log parameters\n",
        "    mlflow.log_param(\"model_type\", \"TabPFNClassifier\")\n",
        "    mlflow.log_param(\"task\", \"otif_risk\")\n",
        "    mlflow.log_param(\"problem_type\", \"multiclass_classification\")\n",
        "    mlflow.log_param(\"n_classes\", 3)\n",
        "    mlflow.log_param(\"test_size\", 0.3)\n",
        "    mlflow.log_param(\"n_features\", X_train_o.shape[1])\n",
        "    mlflow.log_param(\"train_samples\", X_train_o.shape[0])\n",
        "    mlflow.log_param(\"test_samples\", X_test_o.shape[0])\n",
        "    \n",
        "    clf_otif = TabPFNClassifier()\n",
        "    clf_otif.fit(X_train_o, y_train_o)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred_otif = clf_otif.predict(X_test_o)\n",
        "    y_pred_proba_otif = clf_otif.predict_proba(X_test_o)\n",
        "\n",
        "    # Evaluate\n",
        "    accuracy_otif = accuracy_score(y_test_o, y_pred_otif)\n",
        "    \n",
        "    # Log metrics\n",
        "    mlflow.log_metric(\"accuracy\", accuracy_otif)\n",
        "\n",
        "    print(f\"Multi-class Classification Accuracy: {accuracy_otif:.4f}\")\n",
        "    print(f\"MLflow Run ID: {mlflow.active_run().info.run_id}\")\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test_o, y_pred_otif, \n",
        "                                target_names=['Low Risk', 'Medium Risk', 'High Risk']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion Matrix for OTIF Risk\n",
        "cm_otif = confusion_matrix(y_test_o, y_pred_otif)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "im = ax.imshow(cm_otif, interpolation='nearest', cmap='Greens')\n",
        "ax.figure.colorbar(im, ax=ax)\n",
        "\n",
        "classes = ['Low Risk', 'Medium Risk', 'High Risk']\n",
        "ax.set(xticks=np.arange(cm_otif.shape[1]),\n",
        "       yticks=np.arange(cm_otif.shape[0]),\n",
        "       xticklabels=classes, yticklabels=classes,\n",
        "       title='OTIF Risk Prediction - Confusion Matrix',\n",
        "       ylabel='Actual',\n",
        "       xlabel='Predicted')\n",
        "\n",
        "thresh = cm_otif.max() / 2.\n",
        "for i in range(cm_otif.shape[0]):\n",
        "    for j in range(cm_otif.shape[1]):\n",
        "        ax.text(j, i, format(cm_otif[i, j], 'd'),\n",
        "                ha=\"center\", va=\"center\",\n",
        "                color=\"white\" if cm_otif[i, j] > thresh else \"black\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify high-risk orders requiring immediate attention\n",
        "df_test_otif = df_otif.iloc[X_train_o.shape[0]:].copy().reset_index(drop=True)\n",
        "df_test_otif['predicted_risk'] = y_pred_otif\n",
        "df_test_otif['high_risk_probability'] = y_pred_proba_otif[:, 2]  # Probability of High Risk\n",
        "\n",
        "print(\"Top 10 Orders with Highest OTIF Failure Risk:\")\n",
        "high_risk_orders = df_test_otif.nlargest(10, 'high_risk_probability')[[\n",
        "    'order_type', 'customer_tier', 'fulfillment_source', 'carrier_tier',\n",
        "    'inventory_availability_rate', 'days_until_delivery',\n",
        "    'high_risk_probability', 'otif_risk'\n",
        "]]\n",
        "display(high_risk_orders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze OTIF risk by key factors\n",
        "df_test_otif['risk_label'] = df_test_otif['predicted_risk'].map({0: 'Low Risk', 1: 'Medium Risk', 2: 'High Risk'})\n",
        "\n",
        "print(\"Predicted OTIF Risk by Order Type:\")\n",
        "display(pd.crosstab(df_test_otif['order_type'], df_test_otif['risk_label'], normalize='index').round(3) * 100)\n",
        "\n",
        "print(\"\\nPredicted OTIF Risk by Customer Tier:\")\n",
        "display(pd.crosstab(df_test_otif['customer_tier'], df_test_otif['risk_label'], normalize='index').round(3) * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, we demonstrated:\n",
        "\n",
        "- **Binary Classification**: Supplier delay risk prediction with ROC AUC analysis\n",
        "- **Multi-class Classification**: Material shortage risk levels (No Risk, At Risk, Critical)\n",
        "- **Multi-class Classification**: Labor shortage prediction for workforce planning\n",
        "- **Multi-class Classification**: OTIF risk prediction for distribution planning\n",
        "\n",
        "**Key Takeaways:**\n",
        "1. TabPFN provides strong performance without hyperparameter tuning\n",
        "2. Probability outputs enable risk-based decision making\n",
        "3. OTIF prediction enables proactive customer service management\n",
        "\n",
        "**Next Steps:**\n",
        "- Run `02_regression` notebook for price elasticity, promotion lift, and lead time prediction\n",
        "- Explore threshold optimization for different business objectives\n",
        "- Integrate predictions into supply planning, HR, and distribution workflows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
