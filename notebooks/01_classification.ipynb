{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Supply Chain Risk Classification with TabPFN\n",
        "\n",
        "This notebook demonstrates how to use **TabPFN** for classification tasks in retail/CPG supply chain planning.\n",
        "\n",
        "TabPFN is a foundation model for tabular data that outperforms traditional methods while being dramatically faster. It requires no hyperparameter tuning and works out-of-the-box.\n",
        "\n",
        "**Use Cases Covered:**\n",
        "1. **Supplier Delay Risk Prediction** (Binary Classification) - Predict which supplier deliveries will be delayed\n",
        "2. **Material Shortage Prediction** (Multi-class Classification) - Predict material shortage risk levels\n",
        "3. **Labor Shortage Prediction** (Multi-class Classification) - Predict workforce availability issues\n",
        "\n",
        "**Business Value:**\n",
        "- Enable proactive supply risk mitigation\n",
        "- Optimize safety stock and expediting decisions\n",
        "- Improve workforce planning and scheduling\n",
        "- Improve on-time delivery performance\n",
        "\n",
        "**Prerequisites:** Run `00_data_preparation` notebook first to set up the datasets.\n",
        "\n",
        "**References:**\n",
        "- [TabPFN Client GitHub](https://github.com/PriorLabs/tabpfn-client)\n",
        "- [Prior Labs Documentation](https://docs.priorlabs.ai/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute Setup\n",
        "\n",
        "We recommend running this notebook on **Serverless Compute** with the **Base Environment V4**.\n",
        "\n",
        "To configure:\n",
        "1. Click on the compute selector in the notebook toolbar\n",
        "2. Select **Serverless**\n",
        "3. Under Environment, choose **Base Environment V4**\n",
        "\n",
        "Serverless compute provides fast startup times and automatic scaling, ideal for interactive notebook workflows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install tabpfn-client scikit-learn pandas matplotlib --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dbutils.library.restartPython()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Authentication\n",
        "\n",
        "TabPFN client requires authentication using an access token.\n",
        "\n",
        "**Setting up Databricks Secrets (one-time setup):**\n",
        "\n",
        "1. Create a secret scope using the Databricks CLI:\n",
        "   ```bash\n",
        "   databricks secrets create-scope tabpfn-client\n",
        "   ```\n",
        "\n",
        "2. Store your TabPFN token in the secret scope:\n",
        "   ```bash\n",
        "   databricks secrets put-secret tabpfn-client token\n",
        "   ```\n",
        "\n",
        "3. You can retrieve your TabPFN token on another machine by running:\n",
        "   ```python\n",
        "   import tabpfn_client\n",
        "   token = tabpfn_client.get_access_token()\n",
        "   print(token)\n",
        "   ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tabpfn_client\n",
        "\n",
        "token = dbutils.secrets.get(scope=\"tabpfn-client\", key=\"token\")\n",
        "tabpfn_client.set_access_token(token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Configuration\n",
        "\n",
        "Configure the catalog and schema where the prepared datasets are stored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure catalog and schema (must match 00_data_preparation)\n",
        "CATALOG = \"tabpfn_databricks\"\n",
        "SCHEMA = \"default\"\n",
        "\n",
        "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
        "spark.sql(f\"USE SCHEMA {SCHEMA}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from tabpfn_client import TabPFNClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 1: Supply Planning\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Supplier Delay Risk Prediction (Binary Classification)\n",
        "\n",
        "**Business Context:** Supply planners need to identify which incoming supplier deliveries are at risk of delay so they can:\n",
        "- Expedite high-risk orders\n",
        "- Adjust production schedules\n",
        "- Communicate proactively with stakeholders\n",
        "\n",
        "We'll use TabPFN to predict whether a supplier delivery will be delayed based on:\n",
        "- Supplier characteristics (tier, country, reliability history)\n",
        "- Order characteristics (quantity, value, lead time)\n",
        "- External factors (port congestion, weather risk, peak season)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the Supplier Delay Risk dataset from Delta table\n",
        "df_delay = spark.table(\"supplier_delay_risk\").toPandas()\n",
        "\n",
        "print(f\"Dataset shape: {df_delay.shape}\")\n",
        "print(f\"\\nFeatures:\")\n",
        "print([col for col in df_delay.columns if col != 'is_delayed'])\n",
        "print(f\"\\nTarget distribution (is_delayed):\")\n",
        "print(f\"  On-time (0): {(df_delay['is_delayed'] == 0).sum()}\")\n",
        "print(f\"  Delayed (1): {(df_delay['is_delayed'] == 1).sum()}\")\n",
        "print(f\"  Delay rate: {df_delay['is_delayed'].mean():.1%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features - encode categorical columns\n",
        "df_encoded = pd.get_dummies(df_delay, columns=['supplier_tier', 'supplier_country'], drop_first=True)\n",
        "\n",
        "# Separate features and target\n",
        "feature_cols = [col for col in df_encoded.columns if col != 'is_delayed']\n",
        "X = df_encoded[feature_cols].values\n",
        "y = df_delay['is_delayed'].values\n",
        "\n",
        "print(f\"Feature matrix shape: {X.shape}\")\n",
        "print(f\"Number of encoded features: {len(feature_cols)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {len(X_train)}\")\n",
        "print(f\"Test set size: {len(X_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize and train TabPFN classifier\n",
        "clf = TabPFNClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "y_pred_proba = clf.predict_proba(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba[:, 1])\n",
        "\n",
        "print(f\"TabPFN Supplier Delay Risk Prediction Results:\")\n",
        "print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "print(f\"  ROC AUC:  {roc_auc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detailed classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['On-Time', 'Delayed']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize high-risk deliveries\n",
        "# Show deliveries with highest predicted delay probability\n",
        "df_test = df_delay.iloc[X_train.shape[0]:].copy().reset_index(drop=True)\n",
        "df_test['delay_probability'] = y_pred_proba[:, 1]\n",
        "df_test['predicted_delayed'] = y_pred\n",
        "\n",
        "print(\"Top 10 Highest Risk Deliveries:\")\n",
        "high_risk = df_test.nlargest(10, 'delay_probability')[[\n",
        "    'supplier_tier', 'supplier_country', 'contracted_lead_time_days',\n",
        "    'historical_otd_rate', 'port_congestion_index', 'delay_probability', 'is_delayed'\n",
        "]]\n",
        "display(high_risk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Comparison for Supplier Delay Prediction\n",
        "\n",
        "Let's compare TabPFN with other popular classifiers to demonstrate its competitive performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define models to compare\n",
        "models = {\n",
        "    \"TabPFN\": TabPFNClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "}\n",
        "\n",
        "# Cross-validation setup\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Evaluate each model\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    scores = cross_val_score(model, X, y, cv=cv, scoring=\"roc_auc\")\n",
        "    results[name] = {\"mean\": scores.mean(), \"std\": scores.std()}\n",
        "    print(f\"{name:20s}: ROC AUC = {scores.mean():.4f} (+/- {scores.std():.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize comparison\n",
        "df_results = pd.DataFrame(results).T\n",
        "df_results.columns = [\"Mean ROC AUC\", \"Std\"]\n",
        "df_results = df_results.sort_values(\"Mean ROC AUC\", ascending=True)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "colors = [\"#2ecc71\" if name == \"TabPFN\" else \"#3498db\" for name in df_results.index]\n",
        "bars = ax.barh(df_results.index, df_results[\"Mean ROC AUC\"], color=colors)\n",
        "ax.errorbar(df_results[\"Mean ROC AUC\"], df_results.index, \n",
        "            xerr=df_results[\"Std\"], fmt=\"none\", color=\"black\", capsize=3)\n",
        "ax.set_xlabel(\"ROC AUC Score\")\n",
        "ax.set_title(\"Model Comparison - Supplier Delay Risk Prediction\")\n",
        "ax.set_xlim(0.5, 1.0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Material Shortage Prediction (Multi-class Classification)\n",
        "\n",
        "**Business Context:** Material planners need to identify which materials are at risk of shortage to:\n",
        "- Prioritize procurement actions\n",
        "- Expedite critical orders\n",
        "- Adjust production schedules\n",
        "\n",
        "We'll predict shortage risk levels:\n",
        "- **0 = No Risk**: Adequate inventory coverage\n",
        "- **1 = At Risk**: Monitor closely, may need action\n",
        "- **2 = Critical**: Immediate action required"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the Material Shortage dataset from Delta table\n",
        "df_shortage = spark.table(\"material_shortage\").toPandas()\n",
        "\n",
        "print(f\"Dataset shape: {df_shortage.shape}\")\n",
        "print(f\"\\nTarget distribution (shortage_risk):\")\n",
        "shortage_labels = {0: 'No Risk', 1: 'At Risk', 2: 'Critical'}\n",
        "for val, label in shortage_labels.items():\n",
        "    count = (df_shortage['shortage_risk'] == val).sum()\n",
        "    print(f\"  {val} ({label}): {count} ({count/len(df_shortage):.1%})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features - encode categorical columns\n",
        "df_shortage_encoded = pd.get_dummies(df_shortage, \n",
        "                                      columns=['material_type', 'criticality_class'], \n",
        "                                      drop_first=True)\n",
        "\n",
        "# Separate features and target\n",
        "shortage_feature_cols = [col for col in df_shortage_encoded.columns if col != 'shortage_risk']\n",
        "X_shortage = df_shortage_encoded[shortage_feature_cols].values\n",
        "y_shortage = df_shortage['shortage_risk'].values\n",
        "\n",
        "print(f\"Feature matrix shape: {X_shortage.shape}\")\n",
        "\n",
        "# Split the data\n",
        "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(\n",
        "    X_shortage, y_shortage, test_size=0.3, random_state=42, stratify=y_shortage\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train TabPFN on multi-class problem\n",
        "clf_shortage = TabPFNClassifier()\n",
        "clf_shortage.fit(X_train_s, y_train_s)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_shortage = clf_shortage.predict(X_test_s)\n",
        "y_pred_proba_shortage = clf_shortage.predict_proba(X_test_s)\n",
        "\n",
        "# Evaluate\n",
        "accuracy_shortage = accuracy_score(y_test_s, y_pred_shortage)\n",
        "print(f\"Multi-class Classification Accuracy: {accuracy_shortage:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_s, y_pred_shortage, \n",
        "                            target_names=['No Risk', 'At Risk', 'Critical']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test_s, y_pred_shortage)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "im = ax.imshow(cm, interpolation='nearest', cmap='Blues')\n",
        "ax.figure.colorbar(im, ax=ax)\n",
        "\n",
        "classes = ['No Risk', 'At Risk', 'Critical']\n",
        "ax.set(xticks=np.arange(cm.shape[1]),\n",
        "       yticks=np.arange(cm.shape[0]),\n",
        "       xticklabels=classes, yticklabels=classes,\n",
        "       title='Material Shortage Risk - Confusion Matrix',\n",
        "       ylabel='Actual',\n",
        "       xlabel='Predicted')\n",
        "\n",
        "# Add text annotations\n",
        "thresh = cm.max() / 2.\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        ax.text(j, i, format(cm[i, j], 'd'),\n",
        "                ha=\"center\", va=\"center\",\n",
        "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify critical materials requiring immediate attention\n",
        "df_test_shortage = df_shortage.iloc[X_train_s.shape[0]:].copy().reset_index(drop=True)\n",
        "df_test_shortage['predicted_risk'] = y_pred_shortage\n",
        "df_test_shortage['critical_probability'] = y_pred_proba_shortage[:, 2]  # Probability of Critical\n",
        "\n",
        "print(\"Top 10 Materials with Highest Critical Risk Probability:\")\n",
        "critical_materials = df_test_shortage.nlargest(10, 'critical_probability')[[\n",
        "    'material_type', 'criticality_class', 'current_stock_days',\n",
        "    'num_active_suppliers', 'avg_supplier_reliability', \n",
        "    'critical_probability', 'shortage_risk'\n",
        "]]\n",
        "display(critical_materials)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 2: Production Planning\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Labor Shortage Prediction (Multi-class Classification)\n",
        "\n",
        "**Business Context:** Production and HR planners need to anticipate workforce availability issues to:\n",
        "- Schedule overtime or temporary staffing\n",
        "- Adjust production schedules based on labor constraints\n",
        "- Prioritize cross-training initiatives\n",
        "- Improve hiring and retention strategies\n",
        "\n",
        "We'll predict labor shortage risk levels:\n",
        "- **0 = Adequate**: Sufficient workforce coverage\n",
        "- **1 = At Risk**: Monitor closely, may need contingency plans\n",
        "- **2 = Critical**: Immediate staffing action required"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the Labor Shortage dataset from Delta table\n",
        "df_labor = spark.table(\"labor_shortage\").toPandas()\n",
        "\n",
        "print(f\"Dataset shape: {df_labor.shape}\")\n",
        "print(f\"\\nFeatures:\")\n",
        "print([col for col in df_labor.columns if col != 'labor_shortage_risk'])\n",
        "print(f\"\\nTarget distribution (labor_shortage_risk):\")\n",
        "labor_labels = {0: 'Adequate', 1: 'At Risk', 2: 'Critical'}\n",
        "for val, label in labor_labels.items():\n",
        "    count = (df_labor['labor_shortage_risk'] == val).sum()\n",
        "    print(f\"  {val} ({label}): {count} ({count/len(df_labor):.1%})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features - encode categorical columns\n",
        "df_labor_encoded = pd.get_dummies(df_labor, \n",
        "                                   columns=['facility_type', 'facility_size', 'region'], \n",
        "                                   drop_first=True)\n",
        "\n",
        "# Separate features and target\n",
        "labor_feature_cols = [col for col in df_labor_encoded.columns if col != 'labor_shortage_risk']\n",
        "X_labor = df_labor_encoded[labor_feature_cols].values\n",
        "y_labor = df_labor['labor_shortage_risk'].values\n",
        "\n",
        "print(f\"Feature matrix shape: {X_labor.shape}\")\n",
        "\n",
        "# Split the data\n",
        "X_train_l, X_test_l, y_train_l, y_test_l = train_test_split(\n",
        "    X_labor, y_labor, test_size=0.3, random_state=42, stratify=y_labor\n",
        ")\n",
        "print(f\"Training set size: {len(X_train_l)}\")\n",
        "print(f\"Test set size: {len(X_test_l)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train TabPFN on labor shortage prediction\n",
        "clf_labor = TabPFNClassifier()\n",
        "clf_labor.fit(X_train_l, y_train_l)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_labor = clf_labor.predict(X_test_l)\n",
        "y_pred_proba_labor = clf_labor.predict_proba(X_test_l)\n",
        "\n",
        "# Evaluate\n",
        "accuracy_labor = accuracy_score(y_test_l, y_pred_labor)\n",
        "print(f\"Multi-class Classification Accuracy: {accuracy_labor:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_l, y_pred_labor, \n",
        "                            target_names=['Adequate', 'At Risk', 'Critical']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion Matrix for Labor Shortage\n",
        "cm_labor = confusion_matrix(y_test_l, y_pred_labor)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "im = ax.imshow(cm_labor, interpolation='nearest', cmap='Oranges')\n",
        "ax.figure.colorbar(im, ax=ax)\n",
        "\n",
        "classes = ['Adequate', 'At Risk', 'Critical']\n",
        "ax.set(xticks=np.arange(cm_labor.shape[1]),\n",
        "       yticks=np.arange(cm_labor.shape[0]),\n",
        "       xticklabels=classes, yticklabels=classes,\n",
        "       title='Labor Shortage Risk - Confusion Matrix',\n",
        "       ylabel='Actual',\n",
        "       xlabel='Predicted')\n",
        "\n",
        "thresh = cm_labor.max() / 2.\n",
        "for i in range(cm_labor.shape[0]):\n",
        "    for j in range(cm_labor.shape[1]):\n",
        "        ax.text(j, i, format(cm_labor[i, j], 'd'),\n",
        "                ha=\"center\", va=\"center\",\n",
        "                color=\"white\" if cm_labor[i, j] > thresh else \"black\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify facilities with highest labor shortage risk\n",
        "df_test_labor = df_labor.iloc[X_train_l.shape[0]:].copy().reset_index(drop=True)\n",
        "df_test_labor['predicted_risk'] = y_pred_labor\n",
        "df_test_labor['critical_probability'] = y_pred_proba_labor[:, 2]  # Probability of Critical\n",
        "\n",
        "print(\"Top 10 Facilities with Highest Critical Labor Shortage Risk:\")\n",
        "critical_facilities = df_test_labor.nlargest(10, 'critical_probability')[[\n",
        "    'facility_type', 'region', 'current_headcount', 'headcount_ratio',\n",
        "    'turnover_rate_monthly', 'open_positions', 'local_unemployment_rate',\n",
        "    'critical_probability', 'labor_shortage_risk'\n",
        "]]\n",
        "display(critical_facilities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze risk by facility type and region\n",
        "df_test_labor['risk_label'] = df_test_labor['predicted_risk'].map({0: 'Adequate', 1: 'At Risk', 2: 'Critical'})\n",
        "\n",
        "print(\"\\nPredicted Labor Shortage Risk by Facility Type:\")\n",
        "display(pd.crosstab(df_test_labor['facility_type'], df_test_labor['risk_label'], normalize='index').round(3) * 100)\n",
        "\n",
        "print(\"\\nPredicted Labor Shortage Risk by Region:\")\n",
        "display(pd.crosstab(df_test_labor['region'], df_test_labor['risk_label'], normalize='index').round(3) * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 3: Business Impact Analysis\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Business Impact Analysis\n",
        "\n",
        "Let's quantify the potential business impact of using TabPFN for supply chain risk prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate potential business impact for supplier delay prediction\n",
        "print(\"=\" * 60)\n",
        "print(\"BUSINESS IMPACT ANALYSIS: Supplier Delay Risk Prediction\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Assume average delay cost and expediting cost\n",
        "avg_delay_cost = 5000  # Cost per delayed delivery (production disruption, expediting, etc.)\n",
        "expedite_cost = 500    # Cost to proactively expedite a delivery\n",
        "\n",
        "# Without ML: All delays incur full cost\n",
        "total_delays_test = y_test.sum()\n",
        "baseline_cost = total_delays_test * avg_delay_cost\n",
        "\n",
        "# With ML: We expedite high-probability orders, preventing some delays\n",
        "# Assume we expedite orders with >50% delay probability\n",
        "high_risk_mask = y_pred_proba[:, 1] > 0.5\n",
        "expedited_count = high_risk_mask.sum()\n",
        "true_positives = ((y_pred == 1) & (y_test == 1)).sum()  # Correctly identified delays\n",
        "false_positives = ((y_pred == 1) & (y_test == 0)).sum()  # Unnecessary expediting\n",
        "\n",
        "# Assume expediting prevents 80% of delays\n",
        "prevented_delays = int(true_positives * 0.8)\n",
        "missed_delays = total_delays_test - prevented_delays\n",
        "\n",
        "ml_cost = (missed_delays * avg_delay_cost) + (expedited_count * expedite_cost)\n",
        "savings = baseline_cost - ml_cost\n",
        "\n",
        "print(f\"\\nTest Set Statistics:\")\n",
        "print(f\"  Total deliveries: {len(y_test)}\")\n",
        "print(f\"  Actual delays: {total_delays_test}\")\n",
        "print(f\"  Identified as high-risk: {expedited_count}\")\n",
        "\n",
        "print(f\"\\nCost Analysis (assuming ${avg_delay_cost:,} per delay, ${expedite_cost:,} per expedite):\")\n",
        "print(f\"  Baseline cost (no ML): ${baseline_cost:,.0f}\")\n",
        "print(f\"  With TabPFN prediction: ${ml_cost:,.0f}\")\n",
        "print(f\"  Estimated savings: ${savings:,.0f} ({savings/baseline_cost:.1%})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Business impact for labor shortage prediction\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"BUSINESS IMPACT ANALYSIS: Labor Shortage Prediction\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Assumptions for labor shortage costs\n",
        "critical_shortage_cost = 50000  # Cost of critical labor shortage (production delays, overtime, temp staff)\n",
        "at_risk_mitigation_cost = 5000  # Cost to proactively mitigate (overtime planning, early temp hiring)\n",
        "\n",
        "# Count actual critical shortages in test set\n",
        "actual_critical = (y_test_l == 2).sum()\n",
        "actual_at_risk = (y_test_l == 1).sum()\n",
        "\n",
        "# Without ML: All critical shortages incur full cost\n",
        "baseline_labor_cost = actual_critical * critical_shortage_cost\n",
        "\n",
        "# With ML: Predict and mitigate\n",
        "predicted_critical = (y_pred_labor == 2).sum()\n",
        "true_critical = ((y_pred_labor == 2) & (y_test_l == 2)).sum()\n",
        "prevented_critical = int(true_critical * 0.75)  # Assume 75% prevention rate\n",
        "missed_critical = actual_critical - prevented_critical\n",
        "\n",
        "ml_labor_cost = (missed_critical * critical_shortage_cost) + (predicted_critical * at_risk_mitigation_cost)\n",
        "labor_savings = baseline_labor_cost - ml_labor_cost\n",
        "\n",
        "print(f\"\\nTest Set Statistics:\")\n",
        "print(f\"  Total facilities: {len(y_test_l)}\")\n",
        "print(f\"  Actual critical shortages: {actual_critical}\")\n",
        "print(f\"  Predicted as critical: {predicted_critical}\")\n",
        "\n",
        "print(f\"\\nCost Analysis (assuming ${critical_shortage_cost:,} per critical shortage):\")\n",
        "print(f\"  Baseline cost (no ML): ${baseline_labor_cost:,.0f}\")\n",
        "print(f\"  With TabPFN prediction: ${ml_labor_cost:,.0f}\")\n",
        "print(f\"  Estimated savings: ${labor_savings:,.0f} ({labor_savings/max(baseline_labor_cost,1):.1%})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, we demonstrated:\n",
        "\n",
        "- **Binary Classification**: Supplier delay risk prediction with ROC AUC analysis\n",
        "- **Multi-class Classification**: Material shortage risk levels (No Risk, At Risk, Critical)\n",
        "- **Multi-class Classification**: Labor shortage prediction for workforce planning\n",
        "- **Model Comparison**: TabPFN vs. traditional ML algorithms\n",
        "- **Business Impact**: Quantified potential cost savings from proactive risk management\n",
        "\n",
        "**Key Takeaways:**\n",
        "1. TabPFN provides competitive performance without hyperparameter tuning\n",
        "2. Probability outputs enable risk-based decision making\n",
        "3. Supply chain and workforce risk prediction can significantly reduce operational costs\n",
        "\n",
        "**Next Steps:**\n",
        "- Run `02_regression` notebook for price elasticity, promotion lift, and lead time prediction\n",
        "- Explore threshold optimization for different business objectives\n",
        "- Integrate predictions into supply planning and HR workflows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
