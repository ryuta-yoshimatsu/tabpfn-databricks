{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Demand Planning Regression with TabPFN\n",
        "\n",
        "This notebook demonstrates how to use **TabPFN** for regression tasks in retail/CPG demand planning.\n",
        "\n",
        "TabPFN provides state-of-the-art regression performance with built-in uncertainty quantification, making it ideal for scenarios where understanding prediction confidence is important.\n",
        "\n",
        "**Use Cases Covered:**\n",
        "1. **Price Elasticity Prediction** - Understand how price changes affect demand\n",
        "2. **Promotion Lift Prediction** - Predict the sales impact of planned promotions\n",
        "\n",
        "**Business Value:**\n",
        "- Optimize pricing strategies with elasticity insights\n",
        "- Plan promotions with accurate ROI forecasts\n",
        "- Improve demand forecast accuracy\n",
        "\n",
        "**Prerequisites:** Run `00_data_preparation` notebook first to set up the datasets.\n",
        "\n",
        "**References:**\n",
        "- [TabPFN Client GitHub](https://github.com/PriorLabs/tabpfn-client)\n",
        "- [Prior Labs Documentation](https://docs.priorlabs.ai/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute Setup\n",
        "\n",
        "We recommend running this notebook on **Serverless Compute** with the **Base Environment V4**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install tabpfn-client scikit-learn pandas matplotlib seaborn --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dbutils.library.restartPython()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Authentication\n",
        "\n",
        "See the `01_classification` notebook for detailed instructions on setting up Databricks Secrets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tabpfn_client\n",
        "\n",
        "token = dbutils.secrets.get(scope=\"tabpfn-client\", key=\"token\")\n",
        "tabpfn_client.set_access_token(token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CATALOG = \"tabpfn_databricks\"\n",
        "SCHEMA = \"default\"\n",
        "\n",
        "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
        "spark.sql(f\"USE SCHEMA {SCHEMA}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "from tabpfn_client import TabPFNRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Price Elasticity Prediction\n",
        "\n",
        "**Business Context:** Revenue management and demand planning teams need to understand how price changes affect demand to:\n",
        "- Set optimal prices for different products and markets\n",
        "- Plan price increases without losing market share\n",
        "- Design effective discount strategies\n",
        "\n",
        "**Price Elasticity:** Measures the % change in demand for a 1% change in price.\n",
        "- Elasticity of -2.0 means: 1% price increase → 2% demand decrease\n",
        "- More negative = more price sensitive (elastic)\n",
        "- Closer to 0 = less price sensitive (inelastic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Price Elasticity dataset from Delta table\n",
        "df_elasticity = spark.table(\"price_elasticity\").toPandas()\n",
        "\n",
        "print(f\"Dataset shape: {df_elasticity.shape}\")\n",
        "print(f\"\\nFeatures:\")\n",
        "print([col for col in df_elasticity.columns if col != 'price_elasticity'])\n",
        "print(f\"\\nTarget (price_elasticity) statistics:\")\n",
        "print(df_elasticity['price_elasticity'].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize elasticity distribution by category\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "df_elasticity.boxplot(column='price_elasticity', by='category', ax=ax)\n",
        "ax.set_title('Price Elasticity by Product Category')\n",
        "ax.set_xlabel('Category')\n",
        "ax.set_ylabel('Price Elasticity')\n",
        "plt.suptitle('')  # Remove automatic title\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features - encode categorical columns\n",
        "df_elas_encoded = pd.get_dummies(df_elasticity, \n",
        "                                  columns=['category', 'price_tier', 'purchase_frequency'], \n",
        "                                  drop_first=True)\n",
        "\n",
        "# Separate features and target\n",
        "feature_cols = [col for col in df_elas_encoded.columns if col != 'price_elasticity']\n",
        "X = df_elas_encoded[feature_cols].values\n",
        "y = df_elasticity['price_elasticity'].values\n",
        "\n",
        "print(f\"Feature matrix shape: {X.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use a sample for faster demonstration (TabPFN works best with smaller datasets)\n",
        "np.random.seed(42)\n",
        "sample_size = min(2000, len(X))\n",
        "sample_idx = np.random.choice(len(X), size=sample_size, replace=False)\n",
        "X_sample = X[sample_idx]\n",
        "y_sample = y[sample_idx]\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_sample, y_sample, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {len(X_train)}\")\n",
        "print(f\"Test set size: {len(X_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize and train TabPFN regressor\n",
        "reg = TabPFNRegressor()\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = reg.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"TabPFN Price Elasticity Prediction Results:\")\n",
        "print(f\"  RMSE: {rmse:.4f}\")\n",
        "print(f\"  MAE:  {mae:.4f}\")\n",
        "print(f\"  R²:   {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize predictions vs actual values\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "ax.scatter(y_test, y_pred, alpha=0.5, edgecolors='none')\n",
        "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "ax.set_xlabel('Actual Price Elasticity')\n",
        "ax.set_ylabel('Predicted Price Elasticity')\n",
        "ax.set_title(f'Price Elasticity: Predicted vs Actual (R² = {r2:.3f})')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Uncertainty Quantification for Price Elasticity\n",
        "\n",
        "TabPFN can provide prediction intervals, which is valuable for understanding model confidence in elasticity estimates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get predictions with uncertainty (quantiles)\n",
        "# Predict 5th, 50th (median), and 95th percentiles for 90% prediction interval\n",
        "y_lower = reg.predict(X_test, output_type=\"quantiles\", quantiles=[0.05]).flatten()\n",
        "y_median = reg.predict(X_test, output_type=\"quantiles\", quantiles=[0.5]).flatten()\n",
        "y_upper = reg.predict(X_test, output_type=\"quantiles\", quantiles=[0.95]).flatten()\n",
        "\n",
        "# Calculate coverage (what percentage of true values fall within the prediction interval)\n",
        "coverage = np.mean((y_test >= y_lower) & (y_test <= y_upper))\n",
        "print(f\"90% Prediction Interval Coverage: {coverage:.1%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize predictions with uncertainty\n",
        "# Sort by predicted value for better visualization\n",
        "sort_idx = np.argsort(y_median)\n",
        "n_show = 50  # Show first 50 samples for clarity\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "x_range = np.arange(n_show)\n",
        "\n",
        "ax.fill_between(x_range, \n",
        "                y_lower[sort_idx[:n_show]], \n",
        "                y_upper[sort_idx[:n_show]], \n",
        "                alpha=0.3, color='blue', label='90% Prediction Interval')\n",
        "ax.plot(x_range, y_median[sort_idx[:n_show]], 'b-', linewidth=2, label='Predicted (median)')\n",
        "ax.scatter(x_range, y_test[sort_idx[:n_show]], color='red', s=20, label='Actual', zorder=5)\n",
        "\n",
        "ax.set_xlabel('Sample Index (sorted by prediction)')\n",
        "ax.set_ylabel('Price Elasticity')\n",
        "ax.set_title('Price Elasticity Prediction with Uncertainty Quantification')\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Promotion Lift Prediction\n",
        "\n",
        "**Business Context:** Trade promotion managers need to predict the incremental sales lift from promotions to:\n",
        "- Optimize promotion ROI\n",
        "- Plan inventory for promotional periods\n",
        "- Negotiate trade spend with retailers\n",
        "\n",
        "**Promotion Lift:** The % increase in sales during a promotion compared to baseline.\n",
        "- Lift of 100% means: Sales double during the promotion\n",
        "- Higher lift = more effective promotion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Promotion Lift dataset from Delta table\n",
        "df_promo = spark.table(\"promotion_lift\").toPandas()\n",
        "\n",
        "print(f\"Dataset shape: {df_promo.shape}\")\n",
        "print(f\"\\nTarget (promotion_lift_pct) statistics:\")\n",
        "print(df_promo['promotion_lift_pct'].describe())\n",
        "print(f\"\\nPromotion type distribution:\")\n",
        "print(df_promo['promotion_type'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize promotion lift by type\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Box plot by promotion type\n",
        "df_promo.boxplot(column='promotion_lift_pct', by='promotion_type', ax=axes[0])\n",
        "axes[0].set_title('Promotion Lift by Promotion Type')\n",
        "axes[0].set_xlabel('Promotion Type')\n",
        "axes[0].set_ylabel('Lift (%)')\n",
        "plt.suptitle('')\n",
        "\n",
        "# Scatter: Discount Depth vs Lift\n",
        "axes[1].scatter(df_promo['discount_depth_pct'] * 100, df_promo['promotion_lift_pct'], alpha=0.3)\n",
        "axes[1].set_xlabel('Discount Depth (%)')\n",
        "axes[1].set_ylabel('Promotion Lift (%)')\n",
        "axes[1].set_title('Promotion Lift vs Discount Depth')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features - encode categorical columns\n",
        "df_promo_encoded = pd.get_dummies(df_promo, \n",
        "                                   columns=['promotion_type', 'category'], \n",
        "                                   drop_first=True)\n",
        "\n",
        "# Separate features and target\n",
        "promo_feature_cols = [col for col in df_promo_encoded.columns if col != 'promotion_lift_pct']\n",
        "X_promo = df_promo_encoded[promo_feature_cols].values\n",
        "y_promo = df_promo['promotion_lift_pct'].values\n",
        "\n",
        "print(f\"Feature matrix shape: {X_promo.shape}\")\n",
        "\n",
        "# Sample and split\n",
        "np.random.seed(42)\n",
        "sample_size = min(2000, len(X_promo))\n",
        "sample_idx = np.random.choice(len(X_promo), size=sample_size, replace=False)\n",
        "X_promo_sample = X_promo[sample_idx]\n",
        "y_promo_sample = y_promo[sample_idx]\n",
        "\n",
        "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(\n",
        "    X_promo_sample, y_promo_sample, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training: {len(X_train_p)}, Test: {len(X_test_p)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train TabPFN regressor for promotion lift\n",
        "reg_promo = TabPFNRegressor()\n",
        "reg_promo.fit(X_train_p, y_train_p)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_promo = reg_promo.predict(X_test_p)\n",
        "\n",
        "# Evaluate performance\n",
        "rmse_promo = np.sqrt(mean_squared_error(y_test_p, y_pred_promo))\n",
        "mae_promo = mean_absolute_error(y_test_p, y_pred_promo)\n",
        "r2_promo = r2_score(y_test_p, y_pred_promo)\n",
        "\n",
        "print(f\"TabPFN Promotion Lift Prediction Results:\")\n",
        "print(f\"  RMSE: {rmse_promo:.2f}%\")\n",
        "print(f\"  MAE:  {mae_promo:.2f}%\")\n",
        "print(f\"  R²:   {r2_promo:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize predictions vs actual\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "ax.scatter(y_test_p, y_pred_promo, alpha=0.5, edgecolors='none')\n",
        "ax.plot([y_test_p.min(), y_test_p.max()], [y_test_p.min(), y_test_p.max()], 'r--', lw=2)\n",
        "ax.set_xlabel('Actual Promotion Lift (%)')\n",
        "ax.set_ylabel('Predicted Promotion Lift (%)')\n",
        "ax.set_title(f'Promotion Lift: Predicted vs Actual (R² = {r2_promo:.3f})')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Model Comparison\n",
        "\n",
        "Let's compare TabPFN with other popular regression models on both use cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    \"TabPFN\": TabPFNRegressor(),\n",
        "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
        "    \"Ridge Regression\": Ridge(alpha=1.0),\n",
        "}\n",
        "\n",
        "# Evaluate each model on promotion lift prediction\n",
        "print(\"Promotion Lift Prediction - Model Comparison:\")\n",
        "print(\"=\"*60)\n",
        "results_promo = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_p, y_train_p)\n",
        "    y_pred_model = model.predict(X_test_p)\n",
        "    \n",
        "    results_promo[name] = {\n",
        "        \"RMSE\": np.sqrt(mean_squared_error(y_test_p, y_pred_model)),\n",
        "        \"MAE\": mean_absolute_error(y_test_p, y_pred_model),\n",
        "        \"R²\": r2_score(y_test_p, y_pred_model)\n",
        "    }\n",
        "    print(f\"{name:20s}: RMSE = {results_promo[name]['RMSE']:.2f}%, R² = {results_promo[name]['R²']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize comparison\n",
        "df_results = pd.DataFrame(results_promo).T\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# RMSE comparison (lower is better)\n",
        "colors = ['#2ecc71' if name == 'TabPFN' else '#3498db' for name in df_results.index]\n",
        "df_results['RMSE'].sort_values(ascending=False).plot(kind='barh', ax=axes[0], color=colors)\n",
        "axes[0].set_xlabel('RMSE (%) - Lower is better')\n",
        "axes[0].set_title('Model Comparison - RMSE')\n",
        "\n",
        "# R² comparison (higher is better)\n",
        "df_results['R²'].sort_values().plot(kind='barh', ax=axes[1], color=colors)\n",
        "axes[1].set_xlabel('R² - Higher is better')\n",
        "axes[1].set_title('Model Comparison - R²')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Business Application: Promotion ROI Calculator\n",
        "\n",
        "Let's demonstrate how the promotion lift predictions can be used for promotion planning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create sample promotion scenarios\n",
        "df_test_promo = df_promo.iloc[sample_idx][X_train_p.shape[0]:].copy().reset_index(drop=True)\n",
        "df_test_promo['predicted_lift_pct'] = y_pred_promo\n",
        "\n",
        "# Calculate ROI for each promotion\n",
        "# Assumptions:\n",
        "# - Average margin: 30%\n",
        "# - Promo cost = discount_depth * baseline_sales + fixed_cost\n",
        "\n",
        "avg_margin = 0.30\n",
        "fixed_promo_cost = 500  # Display, feature ad costs\n",
        "\n",
        "df_test_promo['baseline_revenue'] = df_test_promo['baseline_weekly_units'] * df_test_promo['base_price_usd']\n",
        "df_test_promo['predicted_promo_units'] = df_test_promo['baseline_weekly_units'] * (1 + df_test_promo['predicted_lift_pct']/100)\n",
        "df_test_promo['promo_revenue'] = df_test_promo['predicted_promo_units'] * df_test_promo['base_price_usd'] * (1 - df_test_promo['discount_depth_pct'])\n",
        "df_test_promo['incremental_revenue'] = df_test_promo['promo_revenue'] - df_test_promo['baseline_revenue']\n",
        "df_test_promo['promo_cost'] = (df_test_promo['discount_depth_pct'] * df_test_promo['promo_revenue']) + fixed_promo_cost\n",
        "df_test_promo['incremental_profit'] = df_test_promo['incremental_revenue'] * avg_margin - df_test_promo['promo_cost']\n",
        "df_test_promo['roi_pct'] = (df_test_promo['incremental_profit'] / df_test_promo['promo_cost']) * 100\n",
        "\n",
        "print(\"Top 10 Highest ROI Promotions:\")\n",
        "top_roi = df_test_promo.nlargest(10, 'roi_pct')[[\n",
        "    'promotion_type', 'category', 'discount_depth_pct', \n",
        "    'predicted_lift_pct', 'incremental_profit', 'roi_pct'\n",
        "]]\n",
        "top_roi['discount_depth_pct'] = (top_roi['discount_depth_pct'] * 100).round(1).astype(str) + '%'\n",
        "top_roi['predicted_lift_pct'] = top_roi['predicted_lift_pct'].round(1).astype(str) + '%'\n",
        "top_roi['roi_pct'] = top_roi['roi_pct'].round(1).astype(str) + '%'\n",
        "top_roi['incremental_profit'] = '$' + top_roi['incremental_profit'].round(0).astype(int).astype(str)\n",
        "display(top_roi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary statistics by promotion type\n",
        "print(\"\\nAverage Predicted Lift by Promotion Type:\")\n",
        "summary = df_test_promo.groupby('promotion_type').agg({\n",
        "    'predicted_lift_pct': 'mean',\n",
        "    'roi_pct': 'mean',\n",
        "    'promotion_type': 'count'\n",
        "}).rename(columns={'promotion_type': 'count'})\n",
        "summary = summary.sort_values('roi_pct', ascending=False)\n",
        "display(summary.round(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, we demonstrated:\n",
        "\n",
        "- ✅ **Price Elasticity Prediction** - Predict price sensitivity by product and market\n",
        "- ✅ **Promotion Lift Prediction** - Forecast incremental sales from promotions\n",
        "- ✅ **Uncertainty Quantification** - Get prediction intervals for risk assessment\n",
        "- ✅ **Model Comparison** - TabPFN vs. traditional regression algorithms\n",
        "- ✅ **Business Application** - Promotion ROI calculation and planning\n",
        "\n",
        "**Key Takeaways:**\n",
        "1. TabPFN provides competitive regression performance without hyperparameter tuning\n",
        "2. Built-in uncertainty quantification enables risk-aware decision making\n",
        "3. Predictions can be directly integrated into pricing and promotion planning workflows\n",
        "\n",
        "**Next Steps:**\n",
        "- Run `03_outlier_detection` notebook for production anomaly detection\n",
        "- Run `04_time_series_forecasting` notebook for demand forecasting\n",
        "- Integrate predictions into demand planning systems"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
