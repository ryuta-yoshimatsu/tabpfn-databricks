{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TabPFN Regression on Databricks\n",
        "\n",
        "This notebook demonstrates how to use **TabPFN** for regression tasks on Databricks.\n",
        "\n",
        "TabPFN provides state-of-the-art regression performance with built-in uncertainty quantification, making it ideal for scenarios where understanding prediction confidence is important.\n",
        "\n",
        "**What you will learn:**\n",
        "- How to perform regression with TabPFN\n",
        "- How to quantify prediction uncertainty\n",
        "- How to compare TabPFN with other regressors\n",
        "\n",
        "**Prerequisites:** Run `00_data_preparation` notebook first to set up the datasets.\n",
        "\n",
        "**References:**\n",
        "- [TabPFN Client GitHub](https://github.com/PriorLabs/tabpfn-client)\n",
        "- [Prior Labs Documentation](https://docs.priorlabs.ai/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute Setup\n",
        "\n",
        "We recommend running this notebook on **Serverless Compute** with the **Base Environment V4**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install tabpfn-client scikit-learn pandas matplotlib seaborn --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dbutils.library.restartPython()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Authentication\n",
        "\n",
        "See the `01_classification` notebook for detailed instructions on setting up Databricks Secrets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tabpfn_client\n",
        "\n",
        "token = dbutils.secrets.get(scope=\"tabpfn-client\", key=\"token\")\n",
        "tabpfn_client.set_access_token(token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CATALOG = \"tabpfn_databricks\"\n",
        "SCHEMA = \"default\"\n",
        "\n",
        "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
        "spark.sql(f\"USE SCHEMA {SCHEMA}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "from tabpfn_client import TabPFNRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Basic Regression Example\n",
        "\n",
        "We'll use the **California Housing** dataset to predict median house values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load California Housing dataset from Delta table\n",
        "df_housing = spark.table(\"california_housing\").toPandas()\n",
        "\n",
        "# Separate features and target\n",
        "feature_names = [col for col in df_housing.columns if col != \"target\"]\n",
        "X = df_housing[feature_names].values\n",
        "y = df_housing[\"target\"].values\n",
        "\n",
        "print(f\"Dataset shape: {X.shape}\")\n",
        "print(f\"Features: {feature_names}\")\n",
        "print(f\"Target: Median house value (in $100,000s)\")\n",
        "print(f\"Target range: [{y.min():.2f}, {y.max():.2f}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use a subset for faster demonstration (TabPFN works best with smaller datasets)\n",
        "np.random.seed(42)\n",
        "sample_idx = np.random.choice(len(X), size=2000, replace=False)\n",
        "X_sample = X[sample_idx]\n",
        "y_sample = y[sample_idx]\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_sample, y_sample, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {len(X_train)}\")\n",
        "print(f\"Test set size: {len(X_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize and train TabPFN regressor\n",
        "reg = TabPFNRegressor()\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = reg.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"TabPFN Regression Results:\")\n",
        "print(f\"  RMSE: {rmse:.4f}\")\n",
        "print(f\"  MAE:  {mae:.4f}\")\n",
        "print(f\"  R²:   {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize predictions vs actual values\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "ax.scatter(y_test, y_pred, alpha=0.5, edgecolors='none')\n",
        "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "ax.set_xlabel('Actual Values')\n",
        "ax.set_ylabel('Predicted Values')\n",
        "ax.set_title(f'TabPFN Regression: Predicted vs Actual (R² = {r2:.3f})')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Uncertainty Quantification\n",
        "\n",
        "TabPFN can provide prediction intervals, which is valuable for understanding model confidence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get predictions with uncertainty (quantiles)\n",
        "# Predict 5th, 50th (median), and 95th percentiles for 90% prediction interval\n",
        "y_lower = reg.predict(X_test, output_type=\"quantiles\", quantiles=[0.05]).flatten()\n",
        "y_median = reg.predict(X_test, output_type=\"quantiles\", quantiles=[0.5]).flatten()\n",
        "y_upper = reg.predict(X_test, output_type=\"quantiles\", quantiles=[0.95]).flatten()\n",
        "\n",
        "print(f\"Shapes - lower: {y_lower.shape}, median: {y_median.shape}, upper: {y_upper.shape}\")\n",
        "\n",
        "# Calculate coverage (what percentage of true values fall within the prediction interval)\n",
        "coverage = np.mean((y_test >= y_lower) & (y_test <= y_upper))\n",
        "print(f\"90% Prediction Interval Coverage: {coverage:.1%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize predictions with uncertainty\n",
        "# Sort by predicted value for better visualization\n",
        "sort_idx = np.argsort(y_median)\n",
        "n_show = 50  # Show first 50 samples for clarity\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "x_range = np.arange(n_show)\n",
        "\n",
        "ax.fill_between(x_range, \n",
        "                y_lower[sort_idx[:n_show]], \n",
        "                y_upper[sort_idx[:n_show]], \n",
        "                alpha=0.3, color='blue', label='90% Prediction Interval')\n",
        "ax.plot(x_range, y_median[sort_idx[:n_show]], 'b-', linewidth=2, label='Predicted (median)')\n",
        "ax.scatter(x_range, y_test[sort_idx[:n_show]], color='red', s=20, label='Actual', zorder=5)\n",
        "\n",
        "ax.set_xlabel('Sample Index (sorted by prediction)')\n",
        "ax.set_ylabel('House Value ($100,000s)')\n",
        "ax.set_title('TabPFN Regression with Uncertainty Quantification')\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Model Comparison\n",
        "\n",
        "Let's compare TabPFN with other popular regression models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    \"TabPFN\": TabPFNRegressor(),\n",
        "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
        "    \"Ridge Regression\": Ridge(alpha=1.0),\n",
        "}\n",
        "\n",
        "# Evaluate each model\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred_model = model.predict(X_test)\n",
        "    \n",
        "    results[name] = {\n",
        "        \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred_model)),\n",
        "        \"MAE\": mean_absolute_error(y_test, y_pred_model),\n",
        "        \"R²\": r2_score(y_test, y_pred_model)\n",
        "    }\n",
        "    print(f\"{name:20s}: RMSE = {results[name]['RMSE']:.4f}, R² = {results[name]['R²']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize comparison\n",
        "df_results = pd.DataFrame(results).T\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# RMSE comparison\n",
        "colors = ['#2ecc71' if name == 'TabPFN' else '#3498db' for name in df_results.index]\n",
        "df_results['RMSE'].sort_values().plot(kind='barh', ax=axes[0], color=colors)\n",
        "axes[0].set_xlabel('RMSE (lower is better)')\n",
        "axes[0].set_title('Model Comparison - RMSE')\n",
        "\n",
        "# R² comparison\n",
        "df_results['R²'].sort_values().plot(kind='barh', ax=axes[1], color=colors)\n",
        "axes[1].set_xlabel('R² (higher is better)')\n",
        "axes[1].set_title('Model Comparison - R²')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, we demonstrated:\n",
        "\n",
        "- ✅ Basic regression with TabPFN\n",
        "- ✅ Uncertainty quantification with prediction intervals\n",
        "- ✅ Model comparison with other popular regressors\n",
        "- ✅ Loading data from Delta tables\n",
        "\n",
        "TabPFN's built-in uncertainty quantification makes it particularly valuable for applications where understanding prediction confidence is critical."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
