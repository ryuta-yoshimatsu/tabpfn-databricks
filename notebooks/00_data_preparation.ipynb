{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preparation for TabPFN Notebooks\n",
        "\n",
        "This notebook downloads and prepares all datasets used in the TabPFN demo notebooks. The datasets are stored as Delta tables in Unity Catalog for easy access.\n",
        "\n",
        "**Datasets prepared:**\n",
        "1. **Breast Cancer Wisconsin** - Binary classification dataset\n",
        "2. **Iris** - Multi-class classification dataset\n",
        "3. **California Housing** - Regression dataset\n",
        "4. **Monash Tourism Monthly** - Time series forecasting dataset\n",
        "\n",
        "**Run this notebook once** to set up all the data before running the other notebooks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute Setup\n",
        "\n",
        "We recommend running this notebook on **Serverless Compute** with the **Base Environment V4**.\n",
        "\n",
        "To configure:\n",
        "1. Click on the compute selector in the notebook toolbar\n",
        "2. Select **Serverless**\n",
        "3. Under Environment, choose **Base Environment V4**\n",
        "\n",
        "Serverless compute provides fast startup times and automatic scaling, ideal for interactive notebook workflows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Install Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install scikit-learn pandas --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dbutils.library.restartPython()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration\n",
        "\n",
        "Define the catalog and schema where datasets will be stored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure your catalog and schema\n",
        "CATALOG = \"tabpfn_databricks\"\n",
        "SCHEMA = \"default\"\n",
        "\n",
        "# Create the catalog and schema if they don't exist\n",
        "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {CATALOG}\")\n",
        "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.{SCHEMA}\")\n",
        "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
        "spark.sql(f\"USE SCHEMA {SCHEMA}\")\n",
        "\n",
        "print(f\"Using catalog: {CATALOG}\")\n",
        "print(f\"Using schema: {SCHEMA}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer, load_iris, fetch_california_housing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Breast Cancer Dataset (Classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Clean column names: replace spaces with underscores (Delta doesn't allow spaces)\n",
        "clean_columns = [col.replace(' ', '_') for col in data.feature_names]\n",
        "df_breast_cancer = pd.DataFrame(data.data, columns=clean_columns)\n",
        "df_breast_cancer[\"target\"] = data.target\n",
        "\n",
        "# Save to Delta table\n",
        "spark.createDataFrame(df_breast_cancer).write.mode(\"overwrite\").saveAsTable(\"breast_cancer\")\n",
        "\n",
        "print(f\"Breast Cancer dataset saved to {CATALOG}.{SCHEMA}.breast_cancer\")\n",
        "print(f\"Shape: {df_breast_cancer.shape}\")\n",
        "print(f\"Classes: {data.target_names.tolist()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Iris Dataset (Multi-class Classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "\n",
        "# Clean column names: replace spaces and parentheses (Delta doesn't allow these)\n",
        "clean_iris_cols = [col.replace(' ', '_').replace('(', '').replace(')', '') for col in iris.feature_names]\n",
        "df_iris = pd.DataFrame(iris.data, columns=clean_iris_cols)\n",
        "df_iris[\"target\"] = iris.target\n",
        "\n",
        "# Save to Delta table\n",
        "spark.createDataFrame(df_iris).write.mode(\"overwrite\").saveAsTable(\"iris\")\n",
        "\n",
        "print(f\"Iris dataset saved to {CATALOG}.{SCHEMA}.iris\")\n",
        "print(f\"Shape: {df_iris.shape}\")\n",
        "print(f\"Classes: {iris.target_names.tolist()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. California Housing Dataset (Regression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load California Housing dataset\n",
        "housing = fetch_california_housing()\n",
        "df_housing = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
        "df_housing[\"target\"] = housing.target\n",
        "\n",
        "# Save to Delta table\n",
        "spark.createDataFrame(df_housing).write.mode(\"overwrite\").saveAsTable(\"california_housing\")\n",
        "\n",
        "print(f\"California Housing dataset saved to {CATALOG}.{SCHEMA}.california_housing\")\n",
        "print(f\"Shape: {df_housing.shape}\")\n",
        "print(f\"Target: Median house value (in $100,000s)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Tourism Monthly Dataset (Time Series)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate synthetic monthly time series data (similar to tourism data)\n",
        "# This avoids HuggingFace compatibility issues on Databricks\n",
        "\n",
        "np.random.seed(42)\n",
        "n_series = 50  # Number of time series\n",
        "n_months = 120  # 10 years of monthly data\n",
        "\n",
        "records = []\n",
        "start_date = pd.Timestamp(\"2010-01-01\")\n",
        "\n",
        "for series_idx in range(n_series):\n",
        "    # Generate realistic tourism-like patterns:\n",
        "    # - Base level varies by series\n",
        "    # - Seasonal pattern (yearly)\n",
        "    # - Trend component\n",
        "    # - Random noise\n",
        "    \n",
        "    base_level = np.random.uniform(500, 5000)\n",
        "    trend = np.random.uniform(-5, 15)  # Monthly trend\n",
        "    seasonal_amplitude = base_level * np.random.uniform(0.2, 0.5)\n",
        "    noise_level = base_level * 0.1\n",
        "    \n",
        "    for month_idx in range(n_months):\n",
        "        timestamp = start_date + pd.DateOffset(months=month_idx)\n",
        "        \n",
        "        # Seasonal component (peaks in summer months)\n",
        "        seasonal = seasonal_amplitude * np.sin(2 * np.pi * (month_idx - 3) / 12)\n",
        "        \n",
        "        # Trend component\n",
        "        trend_component = trend * month_idx\n",
        "        \n",
        "        # Random noise\n",
        "        noise = np.random.normal(0, noise_level)\n",
        "        \n",
        "        # Combine components\n",
        "        value = max(0, base_level + seasonal + trend_component + noise)\n",
        "        \n",
        "        records.append({\n",
        "            \"item_id\": f\"T{series_idx:06d}\",\n",
        "            \"timestamp\": timestamp,\n",
        "            \"target\": float(value)\n",
        "        })\n",
        "\n",
        "df_tourism = pd.DataFrame(records)\n",
        "\n",
        "# Save to Delta table\n",
        "spark.createDataFrame(df_tourism).write.mode(\"overwrite\").saveAsTable(\"tourism_monthly\")\n",
        "\n",
        "print(f\"Tourism Monthly dataset saved to {CATALOG}.{SCHEMA}.tourism_monthly\")\n",
        "print(f\"Number of time series: {n_series}\")\n",
        "print(f\"Total records: {len(df_tourism)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Verify All Tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List all tables in the schema\n",
        "print(f\"Tables in {CATALOG}.{SCHEMA}:\")\n",
        "display(spark.sql(f\"SHOW TABLES IN {CATALOG}.{SCHEMA}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preview each table\n",
        "print(\"Breast Cancer sample:\")\n",
        "display(spark.table(\"breast_cancer\").limit(5))\n",
        "\n",
        "print(\"\\nIris sample:\")\n",
        "display(spark.table(\"iris\").limit(5))\n",
        "\n",
        "print(\"\\nCalifornia Housing sample:\")\n",
        "display(spark.table(\"california_housing\").limit(5))\n",
        "\n",
        "print(\"\\nTourism Monthly sample:\")\n",
        "display(spark.table(\"tourism_monthly\").limit(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "All datasets have been prepared and saved as Delta tables in `tabpfn_databricks.default`:\n",
        "\n",
        "| Table | Description | Usage |\n",
        "|-------|-------------|-------|\n",
        "| `breast_cancer` | Binary classification (569 samples, 30 features) | 01_classification |\n",
        "| `iris` | Multi-class classification (150 samples, 4 features) | 01_classification |\n",
        "| `california_housing` | Regression (20,640 samples, 8 features) | 02_regression |\n",
        "| `tourism_monthly` | Time series forecasting (50 synthetic series, 120 months each) | 04_time_series_forecasting |\n",
        "\n",
        "**Next steps:** Run the individual notebooks (01-04) to explore TabPFN capabilities using these prepared datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
